{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Firm Name Matching: Crunchbase vs Pitchbook\n",
        "\n",
        "This notebook matches firms from Crunchbase (`samplecrunchbase3.csv`) to Pitchbook (`samplepitchbook3.csv`) using the `name_matching` library.\n",
        "\n",
        "## Approach\n",
        "1. **Preprocessing**: Clean company names by removing special characters, collapsing whitespace\n",
        "2. **Name Matching**: Use the `NameMatcher` library with multiple distance metrics:\n",
        "   - `discounted_levenshtein`: Handles character-level edits with position weighting\n",
        "   - `SSK`: String Subsequence Kernel for partial matches\n",
        "   - `fuzzy_wuzzy_token_sort`: Token-based matching that handles word reordering\n",
        "3. **Filtering**: Keep only high-confidence matches (score > 80)\n",
        "4. **Export**: Save results to CSV\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import re\n",
        "from name_matching.name_matcher import NameMatcher\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Display settings\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_colwidth', 100)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the datasets\n",
        "print(\"Loading Crunchbase data...\")\n",
        "df_cb = pd.read_csv(\"samplecrunchbase3.csv\")\n",
        "print(f\"Crunchbase: {len(df_cb):,} companies\")\n",
        "\n",
        "print(\"\\nLoading Pitchbook data...\")\n",
        "df_pb = pd.read_csv(\"samplepitchbook3.csv\")\n",
        "print(f\"Pitchbook: {len(df_pb):,} companies\")\n",
        "\n",
        "print(\"\\n--- Crunchbase Sample ---\")\n",
        "display(df_cb.head())\n",
        "\n",
        "print(\"\\n--- Pitchbook Sample ---\")\n",
        "display(df_pb.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preprocess_company_name(text):\n",
        "    \"\"\"\n",
        "    Preprocess company names for matching:\n",
        "    - Handle missing values\n",
        "    - Replace non-alphanumeric characters with spaces\n",
        "    - Collapse multiple spaces\n",
        "    - Strip leading/trailing whitespace\n",
        "    \"\"\"\n",
        "    if pd.isna(text):\n",
        "        return \"\"\n",
        "    # Replace non-letters/numbers with space\n",
        "    text = re.sub(r\"[^A-Za-z0-9]\", \" \", str(text))\n",
        "    # Collapse multiple spaces into one and strip\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "    return text\n",
        "\n",
        "# Test preprocessing\n",
        "test_names = [\"perplexity.ai\", \"something-ai\", \"facebook, inc.\", \"X.com\", None]\n",
        "print(\"Preprocessing examples:\")\n",
        "for name in test_names:\n",
        "    print(f\"  '{name}' -> '{preprocess_company_name(name)}'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Apply preprocessing to both datasets\n",
        "print(\"Preprocessing company names...\")\n",
        "\n",
        "# Crunchbase: company name is in 'co1' column\n",
        "df_cb[\"co1_clean\"] = df_cb[\"co1\"].apply(preprocess_company_name)\n",
        "\n",
        "# Pitchbook: company name is in 'co2' column\n",
        "df_pb[\"co2_clean\"] = df_pb[\"co2\"].apply(preprocess_company_name)\n",
        "\n",
        "print(f\"\\nCrunchbase cleaned names sample:\")\n",
        "print(df_cb[[\"co1\", \"co1_clean\"]].head(10))\n",
        "\n",
        "print(f\"\\nPitchbook cleaned names sample:\")\n",
        "print(df_pb[[\"co2\", \"co2_clean\"]].head(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# For initial testing, use a sample to verify the matching works\n",
        "# The full dataset has 448K Crunchbase and 86K Pitchbook companies\n",
        "# This would take a very long time, so we'll start with a sample\n",
        "\n",
        "SAMPLE_SIZE_PB = 1000  # Number of Pitchbook companies to match\n",
        "USE_FULL_CB = True     # Use full Crunchbase as master (recommended for accuracy)\n",
        "\n",
        "# Sample Pitchbook data (to be matched)\n",
        "df_pb_sample = df_pb.head(SAMPLE_SIZE_PB).copy()\n",
        "print(f\"Using {len(df_pb_sample):,} Pitchbook companies for matching\")\n",
        "\n",
        "# Use full Crunchbase as master data\n",
        "if USE_FULL_CB:\n",
        "    df_cb_master = df_cb.copy()\n",
        "    print(f\"Using all {len(df_cb_master):,} Crunchbase companies as master data\")\n",
        "else:\n",
        "    df_cb_master = df_cb.head(10000).copy()\n",
        "    print(f\"Using {len(df_cb_master):,} Crunchbase companies as master data (sampled)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize the NameMatcher\n",
        "# Parameters explanation:\n",
        "# - top_n: Number of candidate matches to consider for each name\n",
        "# - lowercase: Convert names to lowercase before matching\n",
        "# - punctuations: Remove punctuation (False = don't remove, we already cleaned)\n",
        "# - remove_ascii: Remove non-ASCII characters\n",
        "# - legal_suffixes: Remove common legal suffixes (Inc, LLC, Corp, etc.)\n",
        "# - common_words: Remove common words that don't help matching\n",
        "# - verbose: Print progress messages\n",
        "\n",
        "print(\"Initializing NameMatcher...\")\n",
        "matcher = NameMatcher(\n",
        "    top_n=10,\n",
        "    lowercase=True,\n",
        "    punctuations=False,\n",
        "    remove_ascii=True,\n",
        "    legal_suffixes=True,\n",
        "    common_words=True,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# Set distance metrics for fuzzy matching\n",
        "# These metrics handle different types of name variations:\n",
        "# - discounted_levenshtein: Character edits with position weighting\n",
        "# - SSK: String Subsequence Kernel for substring matching\n",
        "# - fuzzy_wuzzy_token_sort: Handles word reordering (\"ABC Inc\" vs \"Inc ABC\")\n",
        "matcher.set_distance_metrics([\n",
        "    'discounted_levenshtein',\n",
        "    'SSK',\n",
        "    'fuzzy_wuzzy_token_sort'\n",
        "])\n",
        "print(\"Distance metrics set.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load Crunchbase as master data\n",
        "# This builds the index that will be searched against\n",
        "print(\"Loading master data (Crunchbase)...\")\n",
        "print(\"This may take a few minutes for large datasets...\")\n",
        "\n",
        "matcher.load_and_process_master_data(\n",
        "    column='co1_clean',\n",
        "    df_matching_data=df_cb_master,\n",
        "    transform=True\n",
        ")\n",
        "print(\"Master data loaded!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Perform the name matching\n",
        "# This finds the best match in Crunchbase for each Pitchbook company\n",
        "print(f\"Matching {len(df_pb_sample):,} Pitchbook companies...\")\n",
        "print(\"This may take several minutes...\")\n",
        "\n",
        "matches = matcher.match_names(\n",
        "    to_be_matched=df_pb_sample,\n",
        "    column_matching='co2_clean'\n",
        ")\n",
        "\n",
        "print(f\"\\nMatching complete! Found {len(matches):,} matches.\")\n",
        "print(\"\\nSample matches:\")\n",
        "display(matches.head(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Merge the match results with original data\n",
        "# The matches dataframe contains:\n",
        "# - original_name: The cleaned Pitchbook name\n",
        "# - match_name: The matched Crunchbase name\n",
        "# - score: Match confidence score (0-100)\n",
        "# - match_index: Index in the Crunchbase dataframe\n",
        "\n",
        "print(\"Merging results...\")\n",
        "\n",
        "# First, merge Pitchbook sample with match results\n",
        "combined = pd.merge(\n",
        "    df_pb_sample.reset_index(drop=True),\n",
        "    matches,\n",
        "    how='left',\n",
        "    left_index=True,\n",
        "    right_index=True\n",
        ")\n",
        "\n",
        "# Now bring in the Crunchbase data for matched companies\n",
        "# We'll add the Crunchbase columns based on match_index\n",
        "cb_cols_to_add = ['uuid', 'co1', 'legalname1', 'state1']\n",
        "for col in cb_cols_to_add:\n",
        "    combined[f'cb_{col}'] = combined['match_index'].apply(\n",
        "        lambda idx: df_cb_master.iloc[int(idx)][col] if pd.notna(idx) and idx >= 0 else None\n",
        "    )\n",
        "\n",
        "print(f\"Combined dataset: {len(combined):,} rows\")\n",
        "display(combined.head(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze match score distribution\n",
        "print(\"=== Match Score Distribution ===\")\n",
        "print(combined['score'].describe())\n",
        "\n",
        "print(\"\\n=== Score Buckets ===\")\n",
        "score_buckets = pd.cut(\n",
        "    combined['score'],\n",
        "    bins=[0, 50, 60, 70, 80, 90, 100],\n",
        "    labels=['0-50', '50-60', '60-70', '70-80', '80-90', '90-100']\n",
        ")\n",
        "print(score_buckets.value_counts().sort_index())\n",
        "\n",
        "# Visualize if matplotlib is available\n",
        "try:\n",
        "    import matplotlib.pyplot as plt\n",
        "    fig, ax = plt.subplots(figsize=(10, 5))\n",
        "    combined['score'].hist(bins=50, ax=ax, edgecolor='black')\n",
        "    ax.set_xlabel('Match Score')\n",
        "    ax.set_ylabel('Count')\n",
        "    ax.set_title('Distribution of Match Scores')\n",
        "    ax.axvline(x=80, color='red', linestyle='--', label='Threshold (80)')\n",
        "    ax.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "except ImportError:\n",
        "    print(\"(matplotlib not available for visualization)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Filter to high-confidence matches (score > 80)\n",
        "SCORE_THRESHOLD = 80\n",
        "\n",
        "high_confidence = combined[combined['score'] > SCORE_THRESHOLD].copy()\n",
        "print(f\"High-confidence matches (score > {SCORE_THRESHOLD}): {len(high_confidence):,}\")\n",
        "print(f\"Match rate: {len(high_confidence) / len(combined) * 100:.1f}%\")\n",
        "\n",
        "print(\"\\n=== Sample High-Confidence Matches ===\")\n",
        "display(high_confidence[['co2', 'cb_co1', 'score', 'state2', 'cb_state1']].head(20))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check for exact matches (after cleaning)\n",
        "combined['exact_match'] = combined['co2_clean'].str.lower() == combined['match_name'].str.lower()\n",
        "\n",
        "exact_matches = combined[combined['exact_match']]\n",
        "print(f\"Exact matches (after cleaning): {len(exact_matches):,}\")\n",
        "print(f\"Exact match rate: {len(exact_matches) / len(combined) * 100:.1f}%\")\n",
        "\n",
        "print(\"\\n=== Sample Exact Matches ===\")\n",
        "display(exact_matches[['co2', 'cb_co1', 'score']].head(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze state matching for high-confidence matches\n",
        "# This helps validate match quality - same company should often be in same state\n",
        "\n",
        "# Normalize state codes for comparison\n",
        "high_confidence['state_match'] = (\n",
        "    high_confidence['state2'].str.lower().str.strip() == \n",
        "    high_confidence['cb_state1'].str.lower().str.strip()\n",
        ")\n",
        "\n",
        "state_match_count = high_confidence['state_match'].sum()\n",
        "print(f\"High-confidence matches with same state: {state_match_count:,}\")\n",
        "print(f\"State agreement rate: {state_match_count / len(high_confidence) * 100:.1f}%\")\n",
        "\n",
        "# Show some mismatches for manual review\n",
        "state_mismatches = high_confidence[~high_confidence['state_match']]\n",
        "print(f\"\\n=== State Mismatches (for review) ===\")\n",
        "display(state_mismatches[['co2', 'cb_co1', 'score', 'state2', 'cb_state1']].head(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare final export dataset\n",
        "# Select and rename columns for clarity\n",
        "\n",
        "export_cols = [\n",
        "    'idp',              # Pitchbook ID\n",
        "    'co2',              # Pitchbook company name (original)\n",
        "    'cb_uuid',          # Crunchbase UUID\n",
        "    'cb_co1',           # Crunchbase company name (original)\n",
        "    'cb_legalname1',    # Crunchbase legal name\n",
        "    'score',            # Match score\n",
        "    'exact_match',      # Whether names match exactly after cleaning\n",
        "    'state2',           # Pitchbook state\n",
        "    'cb_state1',        # Crunchbase state\n",
        "]\n",
        "\n",
        "# Filter columns that exist\n",
        "export_cols = [c for c in export_cols if c in combined.columns]\n",
        "\n",
        "export_df = combined[export_cols].copy()\n",
        "\n",
        "# Rename for clarity\n",
        "export_df = export_df.rename(columns={\n",
        "    'idp': 'pitchbook_id',\n",
        "    'co2': 'pitchbook_name',\n",
        "    'cb_uuid': 'crunchbase_uuid',\n",
        "    'cb_co1': 'crunchbase_name',\n",
        "    'cb_legalname1': 'crunchbase_legal_name',\n",
        "    'score': 'match_score',\n",
        "    'state2': 'pitchbook_state',\n",
        "    'cb_state1': 'crunchbase_state'\n",
        "})\n",
        "\n",
        "print(\"Export dataset prepared:\")\n",
        "display(export_df.head(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Export results to CSV\n",
        "# Save all matches\n",
        "all_matches_path = \"firm_matches_all.csv\"\n",
        "export_df.to_csv(all_matches_path, index=False)\n",
        "print(f\"Saved all matches to: {all_matches_path}\")\n",
        "\n",
        "# Save high-confidence matches only\n",
        "high_conf_path = \"firm_matches_high_confidence.csv\"\n",
        "high_conf_export = export_df[export_df['match_score'] > SCORE_THRESHOLD]\n",
        "high_conf_export.to_csv(high_conf_path, index=False)\n",
        "print(f\"Saved high-confidence matches to: {high_conf_path}\")\n",
        "\n",
        "print(f\"\\n=== Summary ===\")\n",
        "print(f\"Total Pitchbook companies processed: {len(export_df):,}\")\n",
        "print(f\"All matches saved: {len(export_df):,}\")\n",
        "print(f\"High-confidence matches (score > {SCORE_THRESHOLD}): {len(high_conf_export):,}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Running on Full Dataset\n",
        "\n",
        "To run on the full dataset:\n",
        "\n",
        "1. Change `SAMPLE_SIZE_PB` to a larger number or set it to `len(df_pb)` \n",
        "2. Be aware this will take significantly longer:\n",
        "   - 86K Pitchbook companies Ã— 448K Crunchbase companies\n",
        "   - Estimated time: Several hours\n",
        "   \n",
        "**Recommendation**: Run in batches or on a machine with more resources.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration for full dataset run (uncomment to use)\n",
        "# WARNING: This will take a long time!\n",
        "\n",
        "# SAMPLE_SIZE_PB = len(df_pb)  # Use all Pitchbook companies\n",
        "# USE_FULL_CB = True           # Use all Crunchbase companies\n",
        "# \n",
        "# # Then re-run cells starting from \"sample-for-testing\"\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
