{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bb9cdb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import ast\n",
    "from collections import Counter\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd39df7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('companies_2024.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f7c6428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "BUSINESS MODEL ANALYSIS\n",
      "============================================================\n",
      "             count percentage\n",
      "platform      3912  15.039213\n",
      "saas          1288   4.951561\n",
      "b2b            487   1.872213\n",
      "marketplace    403   1.549285\n",
      "transaction    196   0.753498\n",
      "b2c            147   0.565124\n",
      "api            102   0.392127\n",
      "protocol        69   0.265262\n",
      "subscription    58   0.222974\n"
     ]
    }
   ],
   "source": [
    "def analyze_business_model(df):\n",
    "    \"\"\"Extract business model indicators from description\"\"\"\n",
    "    business_model_patterns = {\n",
    "        'platform': r'\\bplatform\\b',\n",
    "        'saas': r'\\bsaas\\b|\\bsoftware as a service\\b',\n",
    "        'marketplace': r'\\bmarketplace\\b',\n",
    "        'api': r'\\bapi\\b|\\bapplication programming interface\\b',\n",
    "        'protocol': r'\\bprotocol\\b',\n",
    "        'b2b': r'\\bb2b\\b|\\bbusiness to business\\b|\\benterprise\\b',\n",
    "        'b2c': r'\\bb2c\\b|\\bbusiness to consumer\\b|\\bconsumer\\b',\n",
    "        'marketplace': r'\\bmarketplace\\b',\n",
    "        'subscription': r'\\bsubscription\\b',\n",
    "        'transaction': r'\\btransaction\\b|\\bpayment\\b',\n",
    "    }\n",
    "\n",
    "    results = {}\n",
    "    for model, pattern in business_model_patterns.items():\n",
    "        mask = df['short_description'].str.contains(pattern, case=False, na=False, regex=True)\n",
    "        results[model] = {\n",
    "            'count': mask.sum(),\n",
    "            'percentage': (mask.sum() / len(df)) * 100,\n",
    "            'companies': df[mask]['name'].tolist()[:10]\n",
    "        }\n",
    "    return pd.DataFrame(results).T\n",
    "business_models = analyze_business_model(df)\n",
    "print('=' * 60)\n",
    "print('BUSINESS MODEL ANALYSIS')\n",
    "print('=' * 60)\n",
    "print(business_models[['count', 'percentage']].sort_values('count', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "187445b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "AI Technology Analysis\n",
      "============================================================\n",
      "ai_powered          : 1,699 companies (6.5%)\n",
      "automation          :   749 companies (2.9%)\n",
      "ai_agent            :   202 companies (0.8%)\n",
      "generative_ai       :   201 companies (0.8%)\n",
      "prediction          :   134 companies (0.5%)\n",
      "ai_native           :    81 companies (0.3%)\n",
      "machine_learning    :    74 companies (0.3%)\n",
      "llm                 :    68 companies (0.3%)\n",
      "computer_vision     :    40 companies (0.2%)\n",
      "nlp                 :    12 companies (0.0%)\n",
      "deep_learning       :     8 companies (0.0%)\n",
      "neural_network      :     1 companies (0.0%)\n"
     ]
    }
   ],
   "source": [
    "def analyze_ai_terminology(df):\n",
    "    \"\"\"Deep dive into AI-specific terminology\"\"\"\n",
    "    ai_terms = {\n",
    "        'llm': r'\\bllm\\b|\\blarge language model\\b',\n",
    "        'generative_ai': r'\\bgenerative ai\\b|\\bgenai\\b',\n",
    "        'computer_vision': r'\\bcomputer vision\\b|\\bcv\\b',\n",
    "        'nlp': r'\\bnlp\\b|\\bnatural language processing\\b',\n",
    "        'deep_learning': r'\\bdeep learning\\b',\n",
    "        'neural_network': r'\\bneural network\\b',\n",
    "        'ai_agent': r'\\bai agent\\b|\\bagent\\b',\n",
    "        'ai_powered': r'\\bai.powered\\b|\\bai.driven\\b',\n",
    "        'ai_native': r'\\bai.native\\b',\n",
    "        'machine_learning': r'\\bmachine learning\\b',\n",
    "        'automation': r'\\bautomation\\b|\\bautomate\\b',\n",
    "        'prediction': r'\\bpredict\\w*\\b',\n",
    "    }\n",
    "\n",
    "    results = {}\n",
    "    for term, pattern in ai_terms.items():\n",
    "        mask = df['short_description'].str.contains(pattern, case=False, na=False, regex=True)\n",
    "        results[term] = mask.sum()\n",
    "    return pd.Series(results).sort_values(ascending=False)\n",
    "\n",
    "ai_terms = analyze_ai_terminology(df)\n",
    "print('=' * 60)\n",
    "print('AI Technology Analysis')\n",
    "print('=' * 60)\n",
    "for term, count in ai_terms.items():\n",
    "    print(f\"{term:20s}: {count:5,} companies ({count/len(df)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2df187e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "VALUE PROPOSITION KEYWORDS\n",
      "============================================================\n",
      "automation          : 1,103 companies (4.2%)\n",
      "speed               :   629 companies (2.4%)\n",
      "innovation          :   627 companies (2.4%)\n",
      "security            :   617 companies (2.4%)\n",
      "simplify            :   443 companies (1.7%)\n",
      "optimize            :   384 companies (1.5%)\n",
      "efficiency          :   347 companies (1.3%)\n",
      "scalability         :   325 companies (1.2%)\n",
      "cost_reduction      :   128 companies (0.5%)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 2. VALUE PROPOSITION ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "def analyze_value_propositions(df):\n",
    "    \"\"\"Extract value proposition keywords\"\"\"\n",
    "    value_prop_patterns = {\n",
    "        'automation': r'\\bautomate\\w*\\b|\\bautomation\\b',\n",
    "        'efficiency': r'\\befficien\\w*\\b',\n",
    "        'cost_reduction': r'\\bcost\\b|\\breduce cost\\b|\\bsave money\\b',\n",
    "        'speed': r'\\bfast\\b|\\bquick\\b|\\bspeed\\b|\\breal.time\\b',\n",
    "        'security': r'\\bsecure\\b|\\bsecurity\\b|\\bencrypt\\w*\\b',\n",
    "        'scalability': r'\\bscalable\\b|\\bscale\\b',\n",
    "        'innovation': r'\\binnovative\\b|\\binnovation\\b',\n",
    "        'simplify': r'\\bsimplif\\w*\\b|\\beasy\\b',\n",
    "        'optimize': r'\\boptimiz\\w*\\b',\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    for prop, pattern in value_prop_patterns.items():\n",
    "        mask = df['short_description'].str.contains(pattern, case=False, na=False, regex=True)\n",
    "        results[prop] = mask.sum()\n",
    "    \n",
    "    return pd.Series(results).sort_values(ascending=False)\n",
    "\n",
    "value_props = analyze_value_propositions(df)\n",
    "print(\"=\" * 60)\n",
    "print(\"VALUE PROPOSITION KEYWORDS\")\n",
    "print(\"=\" * 60)\n",
    "for prop, count in value_props.items():\n",
    "    print(f\"{prop:20s}: {count:5,} companies ({count/len(df)*100:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a5db3aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TECHNOLOGY MENTIONS\n",
      "============================================================\n",
      "                   count  percentage\n",
      "ai                6585.0   25.315239\n",
      "cloud              349.0    1.341688\n",
      "blockchain         259.0    0.995694\n",
      "cryptocurrency     235.0    0.903429\n",
      "robotics           222.0    0.853452\n",
      "generative_ai      201.0    0.772720\n",
      "machine_learning   126.0    0.484392\n",
      "api                102.0    0.392127\n",
      "ar_vr               76.0    0.292173\n",
      "iot                 69.0    0.265262\n",
      "llm                 68.0    0.261418\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 3. TECHNOLOGY STACK MENTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def analyze_technology_mentions(df):\n",
    "    \"\"\"Extract specific technology mentions\"\"\"\n",
    "    tech_patterns = {\n",
    "        'ai': r'\\bai\\b|\\bartificial intelligence\\b',\n",
    "        'blockchain': r'\\bblockchain\\b',\n",
    "        'machine_learning': r'\\bmachine learning\\b|\\bml\\b',\n",
    "        'llm': r'\\bllm\\b|\\blarge language model\\b',\n",
    "        'generative_ai': r'\\bgenerative ai\\b|\\bgenai\\b',\n",
    "        'cloud': r'\\bcloud\\b',\n",
    "        'api': r'\\bapi\\b',\n",
    "        'cryptocurrency': r'\\bcryptocurrency\\b|\\bcrypto\\b',\n",
    "        'iot': r'\\biot\\b|\\binternet of things\\b',\n",
    "        'robotics': r'\\brobot\\w*\\b',\n",
    "        'ar_vr': r'\\baugmented reality\\b|\\bvirtual reality\\b|\\bar\\b|\\bvr\\b',\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    for tech, pattern in tech_patterns.items():\n",
    "        mask = df['short_description'].str.contains(pattern, case=False, na=False, regex=True)\n",
    "        results[tech] = {\n",
    "            'count': mask.sum(),\n",
    "            'percentage': (mask.sum() / len(df)) * 100\n",
    "        }\n",
    "    \n",
    "    return pd.DataFrame(results).T.sort_values('count', ascending=False)\n",
    "\n",
    "tech_mentions = analyze_technology_mentions(df)\n",
    "print(\"=\" * 60)\n",
    "print(\"TECHNOLOGY MENTIONS\")\n",
    "print(\"=\" * 60)\n",
    "print(tech_mentions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02383381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TARGET MARKET INDICATORS\n",
      "============================================================\n",
      "finance             :   931 companies (3.6%)\n",
      "healthcare          :   679 companies (2.6%)\n",
      "retail              :   379 companies (1.5%)\n",
      "education           :   311 companies (1.2%)\n",
      "enterprise          :   214 companies (0.8%)\n",
      "consumer            :   123 companies (0.5%)\n",
      "government          :    62 companies (0.2%)\n",
      "smb                 :    40 companies (0.2%)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 4. TARGET MARKET INDICATORS\n",
    "# ============================================================================\n",
    "\n",
    "def analyze_target_markets(df):\n",
    "    \"\"\"Extract target market indicators\"\"\"\n",
    "    market_patterns = {\n",
    "        'enterprise': r'\\benterprise\\b|\\blarge business\\b',\n",
    "        'smb': r'\\bsmall business\\b|\\bsmb\\b|\\bmid.market\\b',\n",
    "        'consumer': r'\\bconsumer\\b|\\bend user\\b|\\bhousehold\\b',\n",
    "        'healthcare': r'\\bhealthcare\\b|\\bhealth care\\b|\\bmedical\\b',\n",
    "        'finance': r'\\bfinance\\b|\\bfinancial\\b|\\bfintech\\b',\n",
    "        'retail': r'\\bretail\\b|\\be.commerce\\b',\n",
    "        'education': r'\\beducation\\b|\\bedtech\\b',\n",
    "        'government': r'\\bgovernment\\b|\\bpublic sector\\b',\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    for market, pattern in market_patterns.items():\n",
    "        mask = df['short_description'].str.contains(pattern, case=False, na=False, regex=True)\n",
    "        results[market] = mask.sum()\n",
    "    \n",
    "    return pd.Series(results).sort_values(ascending=False)\n",
    "\n",
    "target_markets = analyze_target_markets(df)\n",
    "print(\"=\" * 60)\n",
    "print(\"TARGET MARKET INDICATORS\")\n",
    "print(\"=\" * 60)\n",
    "for market, count in target_markets.items():\n",
    "    print(f\"{market:20s}: {count:5,} companies ({count/len(df)*100:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90d542e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "COMPETITIVE POSITIONING LANGUAGE\n",
      "============================================================\n",
      "innovative          :   627 companies (2.4%)\n",
      "cutting_edge        :   487 companies (1.9%)\n",
      "first               :   458 companies (1.8%)\n",
      "leading             :   448 companies (1.7%)\n",
      "revolutionary       :   259 companies (1.0%)\n",
      "only                :   166 companies (0.6%)\n",
      "next_generation     :   132 companies (0.5%)\n",
      "breakthrough        :    16 companies (0.1%)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 5. COMPETITIVE POSITIONING LANGUAGE\n",
    "# ============================================================================\n",
    "\n",
    "def analyze_positioning(df):\n",
    "    \"\"\"Extract competitive positioning language\"\"\"\n",
    "    positioning_patterns = {\n",
    "        'leading': r'\\bleading\\b|\\b#1\\b|\\btop\\b',\n",
    "        'first': r'\\bfirst\\b|\\bpioneer\\w*\\b',\n",
    "        'only': r'\\bonly\\b|\\bunique\\b',\n",
    "        'revolutionary': r'\\brevolutionary\\b|\\brevolutioniz\\w*\\b',\n",
    "        'cutting_edge': r'\\bcutting.edge\\b|\\badvanced\\b',\n",
    "        'next_generation': r'\\bnext.generation\\b|\\bnext gen\\b',\n",
    "        'breakthrough': r'\\bbreakthrough\\b',\n",
    "        'innovative': r'\\binnovative\\b|\\binnovation\\b',\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    for pos, pattern in positioning_patterns.items():\n",
    "        mask = df['short_description'].str.contains(pattern, case=False, na=False, regex=True)\n",
    "        results[pos] = mask.sum()\n",
    "    \n",
    "    return pd.Series(results).sort_values(ascending=False)\n",
    "\n",
    "positioning = analyze_positioning(df)\n",
    "print(\"=\" * 60)\n",
    "print(\"COMPETITIVE POSITIONING LANGUAGE\")\n",
    "print(\"=\" * 60)\n",
    "for pos, count in positioning.items():\n",
    "    print(f\"{pos:20s}: {count:5,} companies ({count/len(df)*100:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "671d9a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ACTION VERB PATTERNS\n",
      "============================================================\n",
      "offers              : 3,178 companies (12.2%)\n",
      "provides            : 3,050 companies (11.7%)\n",
      "develops            : 2,267 companies (8.7%)\n",
      "helps               : 1,471 companies (5.7%)\n",
      "creates             : 1,448 companies (5.6%)\n",
      "builds              :   912 companies (3.5%)\n",
      "supports            :   779 companies (3.0%)\n",
      "connects            :   742 companies (2.9%)\n",
      "delivers            :   590 companies (2.3%)\n",
      "transforms          :   537 companies (2.1%)\n",
      "empowers            :   472 companies (1.8%)\n",
      "enables             :   327 companies (1.3%)\n",
      "revolutionizes      :   226 companies (0.9%)\n",
      "facilitates         :    52 companies (0.2%)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 6. ACTION VERB PATTERNS\n",
    "# ============================================================================\n",
    "\n",
    "def analyze_action_verbs(df):\n",
    "    \"\"\"Extract action verbs from descriptions\"\"\"\n",
    "    action_verbs = {\n",
    "        'develops': r'\\bdevelop\\w*\\b',\n",
    "        'builds': r'\\bbuild\\w*\\b',\n",
    "        'creates': r'\\bcreat\\w*\\b',\n",
    "        'offers': r'\\boffer\\w*\\b',\n",
    "        'provides': r'\\bprovid\\w*\\b',\n",
    "        'delivers': r'\\bdeliver\\w*\\b',\n",
    "        'enables': r'\\benable\\w*\\b',\n",
    "        'empowers': r'\\bempower\\w*\\b',\n",
    "        'facilitates': r'\\bfacilitat\\w*\\b',\n",
    "        'transforms': r'\\btransform\\w*\\b',\n",
    "        'revolutionizes': r'\\brevolutioniz\\w*\\b',\n",
    "        'connects': r'\\bconnect\\w*\\b',\n",
    "        'helps': r'\\bhelp\\w*\\b',\n",
    "        'supports': r'\\bsupport\\w*\\b',\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    for verb, pattern in action_verbs.items():\n",
    "        mask = df['short_description'].str.contains(pattern, case=False, na=False, regex=True)\n",
    "        results[verb] = mask.sum()\n",
    "    \n",
    "    return pd.Series(results).sort_values(ascending=False)\n",
    "\n",
    "action_verbs = analyze_action_verbs(df)\n",
    "print(\"=\" * 60)\n",
    "print(\"ACTION VERB PATTERNS\")\n",
    "print(\"=\" * 60)\n",
    "for verb, count in action_verbs.items():\n",
    "    print(f\"{verb:20s}: {count:5,} companies ({count/len(df)*100:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74b9d8cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "REGULATORY AND COMPLIANCE SIGNALS\n",
      "============================================================\n",
      "secure              :   607 companies (2.3%)\n",
      "compliant           :   329 companies (1.3%)\n",
      "privacy             :    69 companies (0.3%)\n",
      "regulatory          :    55 companies (0.2%)\n",
      "certified           :    41 companies (0.2%)\n",
      "encrypted           :    18 companies (0.1%)\n",
      "gdpr                :     6 companies (0.0%)\n",
      "hipaa               :     5 companies (0.0%)\n",
      "fda                 :     4 companies (0.0%)\n",
      "soc2                :     2 companies (0.0%)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 7. REGULATORY AND COMPLIANCE SIGNALS\n",
    "# ============================================================================\n",
    "\n",
    "def analyze_compliance(df):\n",
    "    \"\"\"Extract regulatory and compliance mentions\"\"\"\n",
    "    compliance_patterns = {\n",
    "        'secure': r'\\bsecure\\b|\\bsecurity\\b',\n",
    "        'encrypted': r'\\bencrypt\\w*\\b',\n",
    "        'compliant': r'\\bcompliant\\b|\\bcompliance\\b',\n",
    "        'gdpr': r'\\bgdpr\\b',\n",
    "        'hipaa': r'\\bhipaa\\b',\n",
    "        'soc2': r'\\bsoc.2\\b|\\bsoc2\\b',\n",
    "        'privacy': r'\\bprivacy\\b',\n",
    "        'certified': r'\\bcertified\\b',\n",
    "        'fda': r'\\bfda\\b',\n",
    "        'regulatory': r'\\bregulatory\\b',\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    for comp, pattern in compliance_patterns.items():\n",
    "        mask = df['short_description'].str.contains(pattern, case=False, na=False, regex=True)\n",
    "        results[comp] = mask.sum()\n",
    "    \n",
    "    return pd.Series(results).sort_values(ascending=False)\n",
    "\n",
    "compliance = analyze_compliance(df)\n",
    "print(\"=\" * 60)\n",
    "print(\"REGULATORY AND COMPLIANCE SIGNALS\")\n",
    "print(\"=\" * 60)\n",
    "for comp, count in compliance.items():\n",
    "    print(f\"{comp:20s}: {count:5,} companies ({count/len(df)*100:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "213c8e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TRENDING CONCEPTS\n",
      "============================================================\n",
      "sustainable         :   280 companies (1.1%)\n",
      "decentralized       :   213 companies (0.8%)\n",
      "web3                :   162 companies (0.6%)\n",
      "autonomous          :   139 companies (0.5%)\n",
      "agentic             :   116 companies (0.4%)\n",
      "carbon              :    85 companies (0.3%)\n",
      "green               :    69 companies (0.3%)\n",
      "renewable           :    65 companies (0.2%)\n",
      "quantum             :    55 companies (0.2%)\n",
      "metaverse           :    19 companies (0.1%)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 8. TRENDING CONCEPTS ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "def analyze_trending_concepts(df):\n",
    "    \"\"\"Identify trending concepts and buzzwords\"\"\"\n",
    "    trending_patterns = {\n",
    "        'agentic': r'\\bagentic\\b',\n",
    "        'autonomous': r'\\bautonomous\\b',\n",
    "        'decentralized': r'\\bdecentralized\\b|\\bdefi\\b',\n",
    "        'sustainable': r'\\bsustainable\\b|\\bsustainability\\b',\n",
    "        'green': r'\\bgreen\\b',\n",
    "        'carbon': r'\\bcarbon\\b',\n",
    "        'renewable': r'\\brenewable\\b',\n",
    "        'web3': r'\\bweb3\\b|\\bweb.3\\b',\n",
    "        'metaverse': r'\\bmetaverse\\b',\n",
    "        'quantum': r'\\bquantum\\b',\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    for trend, pattern in trending_patterns.items():\n",
    "        mask = df['short_description'].str.contains(pattern, case=False, na=False, regex=True)\n",
    "        results[trend] = mask.sum()\n",
    "    \n",
    "    return pd.Series(results).sort_values(ascending=False)\n",
    "\n",
    "trending = analyze_trending_concepts(df)\n",
    "print(\"=\" * 60)\n",
    "print(\"TRENDING CONCEPTS\")\n",
    "print(\"=\" * 60)\n",
    "for trend, count in trending.items():\n",
    "    print(f\"{trend:20s}: {count:5,} companies ({count/len(df)*100:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "222f542e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DESCRIPTION QUALITY METRICS\n",
      "============================================================\n",
      "avg_length                    : 89.84\n",
      "median_length                 : 99.00\n",
      "avg_word_count                : 12.63\n",
      "median_word_count             : 14.00\n",
      "very_short_descriptions       : 2,073\n",
      "vague_descriptions            : 3,802\n",
      "specific_descriptions         : 6,163\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 9. DESCRIPTION QUALITY METRICS\n",
    "# ============================================================================\n",
    "\n",
    "def analyze_description_quality(df):\n",
    "    \"\"\"Analyze description completeness and quality\"\"\"\n",
    "    df['desc_length'] = df['short_description'].str.len()\n",
    "    df['desc_word_count'] = df['short_description'].str.split().str.len()\n",
    "    df['desc_sentence_count'] = df['short_description'].str.count(r'[.!?]')\n",
    "    \n",
    "    # Check for vague descriptions\n",
    "    vague_terms = r'\\bcompany\\b|\\bbusiness\\b|\\borganization\\b'\n",
    "    df['has_vague_terms'] = df['short_description'].str.contains(vague_terms, case=False, na=False, regex=True)\n",
    "    \n",
    "    # Check for specific details\n",
    "    specific_indicators = r'\\bplatform\\b|\\bsoftware\\b|\\bservice\\b|\\bsolution\\b|\\bproduct\\b'\n",
    "    df['has_specific_terms'] = df['short_description'].str.contains(specific_indicators, case=False, na=False, regex=True)\n",
    "    \n",
    "    quality_stats = {\n",
    "        'avg_length': df['desc_length'].mean(),\n",
    "        'median_length': df['desc_length'].median(),\n",
    "        'avg_word_count': df['desc_word_count'].mean(),\n",
    "        'median_word_count': df['desc_word_count'].median(),\n",
    "        'very_short_descriptions': (df['desc_length'] < 30).sum(),\n",
    "        'vague_descriptions': df['has_vague_terms'].sum(),\n",
    "        'specific_descriptions': df['has_specific_terms'].sum(),\n",
    "    }\n",
    "    \n",
    "    return quality_stats\n",
    "\n",
    "quality = analyze_description_quality(df)\n",
    "print(\"=\" * 60)\n",
    "print(\"DESCRIPTION QUALITY METRICS\")\n",
    "print(\"=\" * 60)\n",
    "for metric, value in quality.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"{metric:30s}: {value:.2f}\")\n",
    "    else:\n",
    "        print(f\"{metric:30s}: {value:,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e0237541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "INDUSTRY-SPECIFIC TERMINOLOGY\n",
      "============================================================\n",
      "\n",
      "HEALTHCARE:\n",
      "  patient             :    94 companies\n",
      "  therapeutics        :    91 companies\n",
      "  clinical            :    86 companies\n",
      "  diagnostics         :    56 companies\n",
      "  drug_discovery      :    21 companies\n",
      "\n",
      "FINTECH:\n",
      "  payments            :   361 companies\n",
      "  crypto              :   235 companies\n",
      "  trading             :   201 companies\n",
      "  defi                :    78 companies\n",
      "  lending             :    45 companies\n",
      "\n",
      "ENTERPRISE:\n",
      "  crm                 :   148 companies\n",
      "  workflow            :    77 companies\n",
      "  erp                 :    49 companies\n",
      "  enterprise_software :    11 companies\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 10. INDUSTRY-SPECIFIC TERMINOLOGY CLUSTERS\n",
    "# ============================================================================\n",
    "\n",
    "def analyze_industry_terminology(df):\n",
    "    \"\"\"Extract industry-specific terminology\"\"\"\n",
    "    industry_terms = {\n",
    "        'healthcare': {\n",
    "            'therapeutics': r'\\btherapeutic\\w*\\b',\n",
    "            'diagnostics': r'\\bdiagnostic\\w*\\b',\n",
    "            'clinical': r'\\bclinical\\b',\n",
    "            'patient': r'\\bpatient\\b',\n",
    "            'drug_discovery': r'\\bdrug discovery\\b',\n",
    "        },\n",
    "        'fintech': {\n",
    "            'payments': r'\\bpayment\\w*\\b',\n",
    "            'lending': r'\\blending\\b',\n",
    "            'trading': r'\\btrading\\b',\n",
    "            'defi': r'\\bdefi\\b|\\bdecentralized finance\\b',\n",
    "            'crypto': r'\\bcryptocurrency\\b|\\bcrypto\\b',\n",
    "        },\n",
    "        'enterprise': {\n",
    "            'erp': r'\\berp\\b',\n",
    "            'crm': r'\\bcrm\\b',\n",
    "            'workflow': r'\\bworkflow\\b',\n",
    "            'enterprise_software': r'\\benterprise software\\b',\n",
    "        },\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    for industry, terms in industry_terms.items():\n",
    "        industry_results = {}\n",
    "        for term, pattern in terms.items():\n",
    "            mask = df['short_description'].str.contains(pattern, case=False, na=False, regex=True)\n",
    "            industry_results[term] = mask.sum()\n",
    "        results[industry] = industry_results\n",
    "    \n",
    "    return results\n",
    "\n",
    "industry_terms = analyze_industry_terminology(df)\n",
    "print(\"=\" * 60)\n",
    "print(\"INDUSTRY-SPECIFIC TERMINOLOGY\")\n",
    "print(\"=\" * 60)\n",
    "for industry, terms in industry_terms.items():\n",
    "    print(f\"\\n{industry.upper()}:\")\n",
    "    for term, count in sorted(terms.items(), key=lambda x: x[1], reverse=True):\n",
    "        print(f\"  {term:20s}: {count:5,} companies\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "95240c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TOP 30 COMMON PHRASES (BIGRAMS)\n",
      "============================================================\n",
      "is a                                    : 5,734 occurrences\n",
      "is an                                   : 2,190 occurrences\n",
      "company that                            : 1,352 occurrences\n",
      "platform that                           : 1,157 occurrences\n",
      "that offers                             :  834 occurrences\n",
      "platform for                            :  824 occurrences\n",
      "that provides                           :  566 occurrences\n",
      "in the                                  :  525 occurrences\n",
      "specializes in                          :  518 occurrences\n",
      "an ai                                   :  507 occurrences\n",
      "solutions for                           :  460 occurrences\n",
      "digital marketing                       :  459 occurrences\n",
      "a platform                              :  455 occurrences\n",
      "real estate                             :  432 occurrences\n",
      "an aipowered                            :  430 occurrences\n",
      "designed to                             :  406 occurrences\n",
      "is the                                  :  400 occurrences\n",
      "for the                                 :  374 occurrences\n",
      "that helps                              :  368 occurrences\n",
      "artificial intelligence                 :  353 occurrences\n",
      "specializing in                         :  350 occurrences\n",
      "offers a                                :  343 occurrences\n",
      "to help                                 :  321 occurrences\n",
      "ai is                                   :  293 occurrences\n",
      "focused on                              :  287 occurrences\n",
      "services for                            :  285 occurrences\n",
      "firm that                               :  281 occurrences\n",
      "a software                              :  276 occurrences\n",
      "mobile app                              :  276 occurrences\n",
      "software development                    :  272 occurrences\n",
      "\n",
      "============================================================\n",
      "TOP 20 COMMON PHRASES (TRIGRAMS)\n",
      "============================================================\n",
      "company that offers                               :  427 occurrences\n",
      "is an ai                                          :  331 occurrences\n",
      "is an aipowered                                   :  300 occurrences\n",
      "is a platform                                     :  265 occurrences\n",
      "company that provides                             :  252 occurrences\n",
      "is a software                                     :  244 occurrences\n",
      "is a company                                      :  231 occurrences\n",
      "that specializes in                               :  224 occurrences\n",
      "is an online                                      :  210 occurrences\n",
      "is a digital                                      :  186 occurrences\n",
      "a platform that                                   :  185 occurrences\n",
      "is a technology                                   :  163 occurrences\n",
      "digital marketing agency                          :  162 occurrences\n",
      "ai is a                                           :  162 occurrences\n",
      "platform designed to                              :  155 occurrences\n",
      "platform that helps                               :  144 occurrences\n",
      "a platform for                                    :  140 occurrences\n",
      "technology company that                           :  124 occurrences\n",
      "is an it                                          :  121 occurrences\n",
      "company that develops                             :  120 occurrences\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 11. N-GRAMS AND PHRASE PATTERNS\n",
    "# ============================================================================\n",
    "\n",
    "def extract_ngrams(df, n=2, min_freq=10):\n",
    "    \"\"\"Extract common n-grams (phrases) from descriptions\"\"\"\n",
    "    all_ngrams = []\n",
    "    \n",
    "    for desc in df['short_description'].dropna():\n",
    "        # Clean and tokenize\n",
    "        words = desc.lower().translate(str.maketrans('', '', string.punctuation)).split()\n",
    "        # Create n-grams\n",
    "        for i in range(len(words) - n + 1):\n",
    "            ngram = ' '.join(words[i:i+n])\n",
    "            if len(ngram) > 3:  # Filter very short phrases\n",
    "                all_ngrams.append(ngram)\n",
    "    \n",
    "    ngram_counts = Counter(all_ngrams)\n",
    "    # Filter by minimum frequency\n",
    "    common_ngrams = {phrase: count for phrase, count in ngram_counts.items() if count >= min_freq}\n",
    "    \n",
    "    return pd.Series(common_ngrams).sort_values(ascending=False)\n",
    "\n",
    "# Extract bigrams (2-word phrases)\n",
    "print(\"=\" * 60)\n",
    "print(\"TOP 30 COMMON PHRASES (BIGRAMS)\")\n",
    "print(\"=\" * 60)\n",
    "bigrams = extract_ngrams(df, n=2, min_freq=20)\n",
    "for phrase, count in bigrams.head(30).items():\n",
    "    print(f\"{phrase:40s}: {count:4,} occurrences\")\n",
    "\n",
    "# Extract trigrams (3-word phrases)\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TOP 20 COMMON PHRASES (TRIGRAMS)\")\n",
    "print(\"=\" * 60)\n",
    "trigrams = extract_ngrams(df, n=3, min_freq=10)\n",
    "for phrase, count in trigrams.head(20).items():\n",
    "    print(f\"{phrase:50s}: {count:4,} occurrences\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "207dd351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef calculate_completeness_score(df):\\n\\n    scores = []\\n\\n    for idx, desc in df[\\'short_description\\'].items():\\n        score = 0\\n\\n        # Length score (0-3 points)\\n        if pd.notna(desc):\\n            length = len(desc)\\n            if length > 100:\\n                score += 3\\n            elif length > 50:\\n                score += 2\\n            elif length > 20:\\n                score += 1\\n\\n        # Specificity score (0-2 points)\\n        specific_terms = [\\'platform\\', \\'software\\', \\'service\\', \\'solution\\', \\'product\\', \\'system\\']\\n        if any(term in desc.lower() for term in specific_terms):\\n            score += 2\\n        elif any(term in desc.lower() for term in [\\'company\\', \\'business\\', \\'organization\\']):\\n            score += 1\\n\\n        # Action verb score (0-2 points)\\n        action_verbs = [\\'develops\\', \\'builds\\', \\'creates\\', \\'offers\\', \\'provides\\', \\'enables\\']\\n        if any(verb in desc.lower() for verb in action_verbs):\\n            score += 2\\n\\n        # Technology mention score (0-2 points)\\n        tech_terms = [\\'ai\\', \\'blockchain\\', \\'cloud\\', \\'api\\', \\'software\\', \\'technology\\']\\n        if any(term in desc.lower() for term in tech_terms):\\n            score += 2\\n\\n        # Target market score (0-1 point)\\n        market_terms = [\\'enterprise\\', \\'consumer\\', \\'business\\', \\'customer\\']\\n        if any(term in desc.lower() for term in market_terms):\\n            score += 1\\n\\n        scores.append(score)\\n\\n    return pd.Series(scores, index=df.index)\\n\\ndf[\\'completeness_score\\'] = calculate_completeness_score(df)\\n\\nprint(\"=\" * 60)\\nprint(\"DESCRIPTION COMPLETENESS SCORES\")\\nprint(\"=\" * 60)\\nprint(f\"Average completeness score: {df[\\'completeness_score\\'].mean():.2f}/10\")\\nprint(f\"Median completeness score: {df[\\'completeness_score\\'].median():.2f}/10\")\\nprint(f\"\\nScore distribution:\")\\nprint(df[\\'completeness_score\\'].value_counts().sort_index())\\n\\n# Companies with low completeness\\nlow_completeness = df[df[\\'completeness_score\\'] <= 3]\\nprint(f\"\\nCompanies with low completeness (≤3): {len(low_completeness):,}\")\\nprint(\"\\nSample low-completeness descriptions:\")\\nfor name, desc in zip(low_completeness[\\'name\\'].head(10), low_completeness[\\'short_description\\'].head(10)):\\n    print(f\"  {name}: {desc[:80]}...\")\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 12. DESCRIPTION COMPLETENESS SCORE\n",
    "# ============================================================================\n",
    "\"\"\"\n",
    "def calculate_completeness_score(df):\n",
    "   \n",
    "    scores = []\n",
    "    \n",
    "    for idx, desc in df['short_description'].items():\n",
    "        score = 0\n",
    "        \n",
    "        # Length score (0-3 points)\n",
    "        if pd.notna(desc):\n",
    "            length = len(desc)\n",
    "            if length > 100:\n",
    "                score += 3\n",
    "            elif length > 50:\n",
    "                score += 2\n",
    "            elif length > 20:\n",
    "                score += 1\n",
    "        \n",
    "        # Specificity score (0-2 points)\n",
    "        specific_terms = ['platform', 'software', 'service', 'solution', 'product', 'system']\n",
    "        if any(term in desc.lower() for term in specific_terms):\n",
    "            score += 2\n",
    "        elif any(term in desc.lower() for term in ['company', 'business', 'organization']):\n",
    "            score += 1\n",
    "        \n",
    "        # Action verb score (0-2 points)\n",
    "        action_verbs = ['develops', 'builds', 'creates', 'offers', 'provides', 'enables']\n",
    "        if any(verb in desc.lower() for verb in action_verbs):\n",
    "            score += 2\n",
    "        \n",
    "        # Technology mention score (0-2 points)\n",
    "        tech_terms = ['ai', 'blockchain', 'cloud', 'api', 'software', 'technology']\n",
    "        if any(term in desc.lower() for term in tech_terms):\n",
    "            score += 2\n",
    "        \n",
    "        # Target market score (0-1 point)\n",
    "        market_terms = ['enterprise', 'consumer', 'business', 'customer']\n",
    "        if any(term in desc.lower() for term in market_terms):\n",
    "            score += 1\n",
    "        \n",
    "        scores.append(score)\n",
    "    \n",
    "    return pd.Series(scores, index=df.index)\n",
    "\n",
    "df['completeness_score'] = calculate_completeness_score(df)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"DESCRIPTION COMPLETENESS SCORES\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Average completeness score: {df['completeness_score'].mean():.2f}/10\")\n",
    "print(f\"Median completeness score: {df['completeness_score'].median():.2f}/10\")\n",
    "print(f\"\\nScore distribution:\")\n",
    "print(df['completeness_score'].value_counts().sort_index())\n",
    "\n",
    "# Companies with low completeness\n",
    "low_completeness = df[df['completeness_score'] <= 3]\n",
    "print(f\"\\nCompanies with low completeness (≤3): {len(low_completeness):,}\")\n",
    "print(\"\\nSample low-completeness descriptions:\")\n",
    "for name, desc in zip(low_completeness['name'].head(10), low_completeness['short_description'].head(10)):\n",
    "    print(f\"  {name}: {desc[:80]}...\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "020d8acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "COMPREHENSIVE FEATURE EXTRACTION\n",
      "============================================================\n",
      "Extracted 28 features for 26012 companies\n",
      "\n",
      "Feature summary:\n",
      "desc_length            2336666.0\n",
      "desc_word_count         328447.0\n",
      "desc_sentence_count      20506.0\n",
      "mentions_ai               6585.0\n",
      "is_platform               3912.0\n",
      "uses_offers               3178.0\n",
      "uses_provides             3050.0\n",
      "uses_develops             2267.0\n",
      "is_saas                   1287.0\n",
      "uses_builds                912.0\n",
      "mentions_automation        630.0\n",
      "mentions_security          607.0\n",
      "mentions_secure            607.0\n",
      "targets_healthcare         434.0\n",
      "is_marketplace             403.0\n",
      "uses_innovative            390.0\n",
      "mentions_cloud             349.0\n",
      "mentions_efficiency        347.0\n",
      "uses_enables               327.0\n",
      "mentions_blockchain        259.0\n",
      "uses_leading               225.0\n",
      "targets_enterprise         214.0\n",
      "targets_consumer           112.0\n",
      "is_api                     102.0\n",
      "mentions_ml                 74.0\n",
      "mentions_privacy            69.0\n",
      "mentions_compliant          41.0\n",
      "uses_revolutionary          33.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 13. COMPREHENSIVE FEATURE EXTRACTION\n",
    "# ============================================================================\n",
    "\n",
    "def extract_all_features(df):\n",
    "    \"\"\"Create a comprehensive feature set from descriptions\"\"\"\n",
    "    features = pd.DataFrame(index=df.index)\n",
    "    \n",
    "    # Basic metrics\n",
    "    features['desc_length'] = df['short_description'].str.len()\n",
    "    features['desc_word_count'] = df['short_description'].str.split().str.len()\n",
    "    features['desc_sentence_count'] = df['short_description'].str.count(r'[.!?]')\n",
    "    \n",
    "    # Business model\n",
    "    features['is_platform'] = df['short_description'].str.contains(r'\\bplatform\\b', case=False, na=False, regex=True)\n",
    "    features['is_saas'] = df['short_description'].str.contains(r'\\bsaas\\b', case=False, na=False, regex=True)\n",
    "    features['is_api'] = df['short_description'].str.contains(r'\\bapi\\b', case=False, na=False, regex=True)\n",
    "    features['is_marketplace'] = df['short_description'].str.contains(r'\\bmarketplace\\b', case=False, na=False, regex=True)\n",
    "    \n",
    "    # Technology\n",
    "    features['mentions_ai'] = df['short_description'].str.contains(r'\\bai\\b|\\bartificial intelligence\\b', case=False, na=False, regex=True)\n",
    "    features['mentions_blockchain'] = df['short_description'].str.contains(r'\\bblockchain\\b', case=False, na=False, regex=True)\n",
    "    features['mentions_cloud'] = df['short_description'].str.contains(r'\\bcloud\\b', case=False, na=False, regex=True)\n",
    "    features['mentions_ml'] = df['short_description'].str.contains(r'\\bmachine learning\\b', case=False, na=False, regex=True)\n",
    "    \n",
    "    # Value props\n",
    "    features['mentions_automation'] = df['short_description'].str.contains(r'\\bautomate\\w*\\b', case=False, na=False, regex=True)\n",
    "    features['mentions_security'] = df['short_description'].str.contains(r'\\bsecure\\b|\\bsecurity\\b', case=False, na=False, regex=True)\n",
    "    features['mentions_efficiency'] = df['short_description'].str.contains(r'\\befficien\\w*\\b', case=False, na=False, regex=True)\n",
    "    \n",
    "    # Target market\n",
    "    features['targets_enterprise'] = df['short_description'].str.contains(r'\\benterprise\\b', case=False, na=False, regex=True)\n",
    "    features['targets_consumer'] = df['short_description'].str.contains(r'\\bconsumer\\b', case=False, na=False, regex=True)\n",
    "    features['targets_healthcare'] = df['short_description'].str.contains(r'\\bhealthcare\\b|\\bhealth care\\b', case=False, na=False, regex=True)\n",
    "    \n",
    "    # Positioning\n",
    "    features['uses_leading'] = df['short_description'].str.contains(r'\\bleading\\b', case=False, na=False, regex=True)\n",
    "    features['uses_innovative'] = df['short_description'].str.contains(r'\\binnovative\\b', case=False, na=False, regex=True)\n",
    "    features['uses_revolutionary'] = df['short_description'].str.contains(r'\\brevolutionary\\b', case=False, na=False, regex=True)\n",
    "    \n",
    "    # Action verbs\n",
    "    features['uses_develops'] = df['short_description'].str.contains(r'\\bdevelop\\w*\\b', case=False, na=False, regex=True)\n",
    "    features['uses_builds'] = df['short_description'].str.contains(r'\\bbuild\\w*\\b', case=False, na=False, regex=True)\n",
    "    features['uses_offers'] = df['short_description'].str.contains(r'\\boffer\\w*\\b', case=False, na=False, regex=True)\n",
    "    features['uses_provides'] = df['short_description'].str.contains(r'\\bprovid\\w*\\b', case=False, na=False, regex=True)\n",
    "    features['uses_enables'] = df['short_description'].str.contains(r'\\benable\\w*\\b', case=False, na=False, regex=True)\n",
    "    \n",
    "    # Compliance\n",
    "    features['mentions_secure'] = df['short_description'].str.contains(r'\\bsecure\\b|\\bsecurity\\b', case=False, na=False, regex=True)\n",
    "    features['mentions_privacy'] = df['short_description'].str.contains(r'\\bprivacy\\b', case=False, na=False, regex=True)\n",
    "    features['mentions_compliant'] = df['short_description'].str.contains(r'\\bcompliant\\b', case=False, na=False, regex=True)\n",
    "    \n",
    "    # Convert boolean to int\n",
    "    bool_cols = features.select_dtypes(include=['bool']).columns\n",
    "    features[bool_cols] = features[bool_cols].astype(int)\n",
    "    \n",
    "    return features\n",
    "\n",
    "description_features = extract_all_features(df)\n",
    "print(\"=\" * 60)\n",
    "print(\"COMPREHENSIVE FEATURE EXTRACTION\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Extracted {len(description_features.columns)} features for {len(description_features)} companies\")\n",
    "print(\"\\nFeature summary:\")\n",
    "print(description_features.sum().sort_values(ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6735d023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SECTOR-SPECIFIC DESCRIPTION PATTERNS\n",
      "============================================================\n",
      "             count  avg_length  avg_words  mentions_ai  mentions_platform  \\\n",
      "AI          5036.0   94.620258  13.245680       3586.0             1092.0   \n",
      "Blockchain   620.0   92.285484  12.900000        114.0              129.0   \n",
      "Healthcare  1302.0   96.559140  13.218894        333.0              196.0   \n",
      "FinTech      814.0   93.750614  12.993857        191.0              204.0   \n",
      "\n",
      "            avg_completeness  \n",
      "AI                       0.0  \n",
      "Blockchain               0.0  \n",
      "Healthcare               0.0  \n",
      "FinTech                  0.0  \n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 14. SECTOR-SPECIFIC DESCRIPTION ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "def analyze_sector_descriptions(df):\n",
    "    \"\"\"Compare description patterns across different sectors\"\"\"\n",
    "    sectors = {\n",
    "        'AI': df['categories'].str.contains('Artificial Intelligence', na=False, case=False),\n",
    "        'Blockchain': df['categories'].str.contains('Blockchain', na=False, case=False),\n",
    "        'Healthcare': df['categories'].str.contains('Health Care', na=False, case=False),\n",
    "        'FinTech': df['categories'].str.contains('FinTech', na=False, case=False),\n",
    "    }\n",
    "    \n",
    "    sector_stats = {}\n",
    "    for sector_name, mask in sectors.items():\n",
    "        sector_df = df[mask]\n",
    "        if len(sector_df) > 0:\n",
    "            sector_stats[sector_name] = {\n",
    "                'count': len(sector_df),\n",
    "                'avg_length': sector_df['short_description'].str.len().mean(),\n",
    "                'avg_words': sector_df['short_description'].str.split().str.len().mean(),\n",
    "                'mentions_ai': sector_df['short_description'].str.contains(r'\\bai\\b', case=False, na=False, regex=True).sum(),\n",
    "                'mentions_platform': sector_df['short_description'].str.contains(r'\\bplatform\\b', case=False, na=False, regex=True).sum(),\n",
    "                'avg_completeness': sector_df['completeness_score'].mean() if 'completeness_score' in sector_df.columns else 0,\n",
    "            }\n",
    "    \n",
    "    return pd.DataFrame(sector_stats).T\n",
    "\n",
    "sector_comparison = analyze_sector_descriptions(df)\n",
    "print(\"=\" * 60)\n",
    "print(\"SECTOR-SPECIFIC DESCRIPTION PATTERNS\")\n",
    "print(\"=\" * 60)\n",
    "print(sector_comparison)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "58d0de55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Description features saved to 'description_features.csv'\n",
      "Summary statistics saved to 'description_analysis_summary.csv'\n",
      "\n",
      "============================================================\n",
      "ANALYSIS COMPLETE!\n",
      "============================================================\n",
      "Analyzed 26,012 company descriptions\n",
      "Results exported to CSV files:\n",
      "  - description_features.csv (comprehensive feature matrix)\n",
      "  - description_analysis_summary.csv (summary statistics)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 15. EXPORT RESULTS\n",
    "# ============================================================================\n",
    "\n",
    "# Save comprehensive features\n",
    "description_features.to_csv('description_features.csv', index=False)\n",
    "print(\"Description features saved to 'description_features.csv'\")\n",
    "\n",
    "# Create summary statistics\n",
    "summary_data = {\n",
    "    'Analysis_Type': [],\n",
    "    'Metric': [],\n",
    "    'Count': [],\n",
    "    'Percentage': []\n",
    "}\n",
    "\n",
    "# Business Models\n",
    "for model, row in business_models.iterrows():\n",
    "    summary_data['Analysis_Type'].append('Business Model')\n",
    "    summary_data['Metric'].append(model)\n",
    "    summary_data['Count'].append(int(row['count']))\n",
    "    summary_data['Percentage'].append(row['percentage'])\n",
    "\n",
    "# Value Propositions\n",
    "for prop, count in value_props.items():\n",
    "    summary_data['Analysis_Type'].append('Value Proposition')\n",
    "    summary_data['Metric'].append(prop)\n",
    "    summary_data['Count'].append(int(count))\n",
    "    summary_data['Percentage'].append((count / len(df)) * 100)\n",
    "\n",
    "# Technology Mentions\n",
    "for tech, row in tech_mentions.iterrows():\n",
    "    summary_data['Analysis_Type'].append('Technology')\n",
    "    summary_data['Metric'].append(tech)\n",
    "    summary_data['Count'].append(int(row['count']))\n",
    "    summary_data['Percentage'].append(row['percentage'])\n",
    "\n",
    "# Target Markets\n",
    "for market, count in target_markets.items():\n",
    "    summary_data['Analysis_Type'].append('Target Market')\n",
    "    summary_data['Metric'].append(market)\n",
    "    summary_data['Count'].append(int(count))\n",
    "    summary_data['Percentage'].append((count / len(df)) * 100)\n",
    "\n",
    "# AI Terminology\n",
    "for term, count in ai_terms.items():\n",
    "    summary_data['Analysis_Type'].append('AI Terminology')\n",
    "    summary_data['Metric'].append(term)\n",
    "    summary_data['Count'].append(int(count))\n",
    "    summary_data['Percentage'].append((count / len(df)) * 100)\n",
    "\n",
    "# Positioning\n",
    "for pos, count in positioning.items():\n",
    "    summary_data['Analysis_Type'].append('Positioning')\n",
    "    summary_data['Metric'].append(pos)\n",
    "    summary_data['Count'].append(int(count))\n",
    "    summary_data['Percentage'].append((count / len(df)) * 100)\n",
    "\n",
    "# Action Verbs\n",
    "for verb, count in action_verbs.items():\n",
    "    summary_data['Analysis_Type'].append('Action Verb')\n",
    "    summary_data['Metric'].append(verb)\n",
    "    summary_data['Count'].append(int(count))\n",
    "    summary_data['Percentage'].append((count / len(df)) * 100)\n",
    "\n",
    "# Compliance\n",
    "for comp, count in compliance.items():\n",
    "    summary_data['Analysis_Type'].append('Compliance')\n",
    "    summary_data['Metric'].append(comp)\n",
    "    summary_data['Count'].append(int(count))\n",
    "    summary_data['Percentage'].append((count / len(df)) * 100)\n",
    "\n",
    "# Trending Concepts\n",
    "for trend, count in trending.items():\n",
    "    summary_data['Analysis_Type'].append('Trending Concept')\n",
    "    summary_data['Metric'].append(trend)\n",
    "    summary_data['Count'].append(int(count))\n",
    "    summary_data['Percentage'].append((count / len(df)) * 100)\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "summary_df.to_csv('description_analysis_summary.csv', index=False)\n",
    "print(\"Summary statistics saved to 'description_analysis_summary.csv'\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ANALYSIS COMPLETE!\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Analyzed {len(df):,} company descriptions\")\n",
    "print(\"Results exported to CSV files:\")\n",
    "print(\"  - description_features.csv (comprehensive feature matrix)\")\n",
    "print(\"  - description_analysis_summary.csv (summary statistics)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dab3b874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "AI MENTIONS IN COMPANY DESCRIPTIONS - ANALYSIS SUMMARY\n",
      "================================================================================\n",
      "\n",
      "Generated: 2025-11-15 12:09:32\n",
      "\n",
      "OVERALL STATISTICS\n",
      "--------------------------------------------------------------------------------\n",
      "Total Companies Analyzed: 26,012\n",
      "Companies Mentioning AI in Description: 6,693 (25.73%)\n",
      "Companies with AI Category: 5,036 (19.36%)\n",
      "Companies with Both Description & Category: 3,790\n",
      "Companies with Either Description OR Category: 7,939 (30.52%)\n",
      "Description Only (no AI category): 2,903\n",
      "Category Only (no AI in description): 1,246\n",
      "Neither Description nor Category: 18,073\n",
      "\n",
      "AI TERMINOLOGY BREAKDOWN\n",
      "--------------------------------------------------------------------------------\n",
      "  Ai Direct                     :  6,338 companies (24.37%)\n",
      "  Ai Powered                    :  1,699 companies ( 6.53%)\n",
      "  Artificial Intelligence       :    367 companies ( 1.41%)\n",
      "  Generative Ai                 :    201 companies ( 0.77%)\n",
      "  Machine Learning              :    126 companies ( 0.48%)\n",
      "  Ai Native                     :     81 companies ( 0.31%)\n",
      "  Ai Agent                      :     80 companies ( 0.31%)\n",
      "  Llm                           :     68 companies ( 0.26%)\n",
      "  Computer Vision               :     32 companies ( 0.12%)\n",
      "  Nlp                           :     12 companies ( 0.05%)\n",
      "  Deep Learning                 :      8 companies ( 0.03%)\n",
      "  Neural Network                :      1 companies ( 0.00%)\n",
      "\n",
      "SECTOR-SPECIFIC AI MENTIONS\n",
      "--------------------------------------------------------------------------------\n",
      "Software:\n",
      "  Total Companies: 5,552\n",
      "  Mentioning AI: 2,307 (41.55%)\n",
      "\n",
      "SaaS:\n",
      "  Total Companies: 1,896\n",
      "  Mentioning AI: 824 (43.46%)\n",
      "\n",
      "Health Care:\n",
      "  Total Companies: 1,302\n",
      "  Mentioning AI: 355 (27.27%)\n",
      "\n",
      "FinTech:\n",
      "  Total Companies: 814\n",
      "  Mentioning AI: 198 (24.32%)\n",
      "\n",
      "Blockchain:\n",
      "  Total Companies: 620\n",
      "  Mentioning AI: 118 (19.03%)\n",
      "\n",
      "Robotics:\n",
      "  Total Companies: 234\n",
      "  Mentioning AI: 79 (33.76%)\n",
      "\n",
      "================================================================================\n",
      "Summary saved to: ai_mentions_summary.csv\n",
      "Pattern breakdown saved to: ai_patterns_breakdown.csv\n",
      "Sector breakdown saved to: ai_sector_breakdown.csv\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['founded_date'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 165\u001b[39m\n\u001b[32m    162\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mSector breakdown saved to: ai_sector_breakdown.csv\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    164\u001b[39m \u001b[38;5;66;03m# Export list of AI companies\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m165\u001b[39m ai_companies_export = \u001b[43mdf_ai\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdf_ai\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmentions_ai\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mname\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mshort_description\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcategories\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mfounded_date\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m.copy()\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33memployees_midpoint\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m df_ai.columns:\n\u001b[32m    167\u001b[39m     ai_companies_export[\u001b[33m'\u001b[39m\u001b[33memployees_midpoint\u001b[39m\u001b[33m'\u001b[39m] = df_ai[df_ai[\u001b[33m'\u001b[39m\u001b[33mmentions_ai\u001b[39m\u001b[33m'\u001b[39m]][\u001b[33m'\u001b[39m\u001b[33memployees_midpoint\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Research/.venv/lib/python3.14/site-packages/pandas/core/frame.py:4119\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4117\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[32m   4118\u001b[39m         key = \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m4119\u001b[39m     indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumns\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m]\n\u001b[32m   4121\u001b[39m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[32m   4122\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Research/.venv/lib/python3.14/site-packages/pandas/core/indexes/base.py:6212\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n\u001b[32m   6209\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6210\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n\u001b[32m-> \u001b[39m\u001b[32m6212\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6214\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n\u001b[32m   6215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[32m   6216\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Research/.venv/lib/python3.14/site-packages/pandas/core/indexes/base.py:6264\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n\u001b[32m   6261\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6263\u001b[39m not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n\u001b[32m-> \u001b[39m\u001b[32m6264\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"['founded_date'] not in index\""
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# AI MENTIONS ANALYSIS - FOCUSED ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "def analyze_ai_mentions_focused(df):\n",
    "    \"\"\"Comprehensive analysis of AI mentions in descriptions\"\"\"\n",
    "    \n",
    "    # Define AI-related patterns\n",
    "    ai_patterns = {\n",
    "        'ai_direct': r'\\bai\\b',\n",
    "        'artificial_intelligence': r'\\bartificial intelligence\\b',\n",
    "        'machine_learning': r'\\bmachine learning\\b|\\bml\\b',\n",
    "        'deep_learning': r'\\bdeep learning\\b',\n",
    "        'neural_network': r'\\bneural network\\b',\n",
    "        'llm': r'\\bllm\\b|\\blarge language model\\b',\n",
    "        'generative_ai': r'\\bgenerative ai\\b|\\bgenai\\b',\n",
    "        'computer_vision': r'\\bcomputer vision\\b',\n",
    "        'nlp': r'\\bnlp\\b|\\bnatural language processing\\b',\n",
    "        'ai_powered': r'\\bai.powered\\b|\\bai.driven\\b',\n",
    "        'ai_native': r'\\bai.native\\b',\n",
    "        'ai_agent': r'\\bai agent\\b',\n",
    "    }\n",
    "    \n",
    "    # Check for any AI mention (broad)\n",
    "    broad_ai_pattern = r'\\bai\\b|\\bartificial intelligence\\b|\\bmachine learning\\b|\\bdeep learning\\b|\\bneural\\b|\\bllm\\b|\\bgenerative ai\\b|\\bgenai\\b'\n",
    "    df['mentions_ai'] = df['short_description'].str.contains(broad_ai_pattern, case=False, na=False, regex=True)\n",
    "    \n",
    "    # Check for AI category\n",
    "    df['has_ai_category'] = df['categories'].str.contains('Artificial Intelligence', na=False, case=False)\n",
    "    \n",
    "    # Detailed pattern matching\n",
    "    pattern_counts = {}\n",
    "    for pattern_name, pattern in ai_patterns.items():\n",
    "        mask = df['short_description'].str.contains(pattern, case=False, na=False, regex=True)\n",
    "        pattern_counts[pattern_name] = mask.sum()\n",
    "    \n",
    "    return df, pattern_counts\n",
    "\n",
    "# Run analysis\n",
    "df_ai, pattern_counts = analyze_ai_mentions_focused(df)\n",
    "\n",
    "# Calculate statistics\n",
    "total_companies = len(df_ai)\n",
    "ai_in_description = df_ai['mentions_ai'].sum()\n",
    "ai_in_category = df_ai['has_ai_category'].sum()\n",
    "both_ai = (df_ai['mentions_ai'] & df_ai['has_ai_category']).sum()\n",
    "either_ai = (df_ai['mentions_ai'] | df_ai['has_ai_category']).sum()\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"AI MENTIONS IN COMPANY DESCRIPTIONS - ANALYSIS SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nGenerated: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "\n",
    "print(\"OVERALL STATISTICS\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"Total Companies Analyzed: {total_companies:,}\")\n",
    "print(f\"Companies Mentioning AI in Description: {ai_in_description:,} ({ai_in_description/total_companies*100:.2f}%)\")\n",
    "print(f\"Companies with AI Category: {ai_in_category:,} ({ai_in_category/total_companies*100:.2f}%)\")\n",
    "print(f\"Companies with Both Description & Category: {both_ai:,}\")\n",
    "print(f\"Companies with Either Description OR Category: {either_ai:,} ({either_ai/total_companies*100:.2f}%)\")\n",
    "print(f\"Description Only (no AI category): {(df_ai['mentions_ai'] & ~df_ai['has_ai_category']).sum():,}\")\n",
    "print(f\"Category Only (no AI in description): {(~df_ai['mentions_ai'] & df_ai['has_ai_category']).sum():,}\")\n",
    "print(f\"Neither Description nor Category: {(~df_ai['mentions_ai'] & ~df_ai['has_ai_category']).sum():,}\")\n",
    "\n",
    "print(\"\\nAI TERMINOLOGY BREAKDOWN\")\n",
    "print(\"-\" * 80)\n",
    "sorted_patterns = sorted(pattern_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "for pattern, count in sorted_patterns:\n",
    "    pct = (count / total_companies) * 100\n",
    "    print(f\"  {pattern.replace('_', ' ').title():30s}: {count:6,} companies ({pct:5.2f}%)\")\n",
    "\n",
    "# Company size analysis for AI companies\n",
    "ai_companies = df_ai[df_ai['mentions_ai']]\n",
    "if len(ai_companies) > 0 and 'employees_midpoint' in ai_companies.columns:\n",
    "    print(\"\\nAI COMPANY SIZE ANALYSIS\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"Average Employees (AI Companies): {ai_companies['employees_midpoint'].mean():.1f}\")\n",
    "    print(f\"Median Employees (AI Companies): {ai_companies['employees_midpoint'].median():.1f}\")\n",
    "    print(f\"Small Companies (1-10 employees): {(ai_companies['employees_min'] <= 10).sum():,}\")\n",
    "    print(f\"Medium Companies (11-50 employees): {((ai_companies['employees_min'] > 10) & (ai_companies['employees_max'] <= 50)).sum():,}\")\n",
    "    print(f\"Large Companies (51+ employees): {(ai_companies['employees_min'] > 50).sum():,}\")\n",
    "\n",
    "# Sector analysis\n",
    "print(\"\\nSECTOR-SPECIFIC AI MENTIONS\")\n",
    "print(\"-\" * 80)\n",
    "sectors = {\n",
    "    'Software': df_ai['categories'].str.contains('Software', na=False, case=False),\n",
    "    'SaaS': df_ai['categories'].str.contains('SaaS', na=False, case=False),\n",
    "    'Health Care': df_ai['categories'].str.contains('Health Care', na=False, case=False),\n",
    "    'FinTech': df_ai['categories'].str.contains('FinTech', na=False, case=False),\n",
    "    'Blockchain': df_ai['categories'].str.contains('Blockchain', na=False, case=False),\n",
    "    'Robotics': df_ai['categories'].str.contains('Robotics', na=False, case=False),\n",
    "}\n",
    "\n",
    "sector_stats = []\n",
    "for sector_name, mask in sectors.items():\n",
    "    sector_df = df_ai[mask]\n",
    "    if len(sector_df) > 0:\n",
    "        sector_ai = sector_df['mentions_ai'].sum()\n",
    "        pct_ai = (sector_ai / len(sector_df)) * 100\n",
    "        sector_stats.append({\n",
    "            'Sector': sector_name,\n",
    "            'Total': len(sector_df),\n",
    "            'Mentions AI': sector_ai,\n",
    "            'Percentage': pct_ai\n",
    "        })\n",
    "        print(f\"{sector_name}:\")\n",
    "        print(f\"  Total Companies: {len(sector_df):,}\")\n",
    "        print(f\"  Mentioning AI: {sector_ai:,} ({pct_ai:.2f}%)\")\n",
    "        print()\n",
    "\n",
    "# Export summary to CSV\n",
    "summary_data = {\n",
    "    'Metric': [\n",
    "        'Total Companies',\n",
    "        'Mentions AI in Description',\n",
    "        'Has AI Category',\n",
    "        'Both Description and Category',\n",
    "        'Either Description or Category',\n",
    "        'Description Only',\n",
    "        'Category Only',\n",
    "        'Neither'\n",
    "    ],\n",
    "    'Count': [\n",
    "        total_companies,\n",
    "        ai_in_description,\n",
    "        ai_in_category,\n",
    "        both_ai,\n",
    "        either_ai,\n",
    "        (df_ai['mentions_ai'] & ~df_ai['has_ai_category']).sum(),\n",
    "        (~df_ai['mentions_ai'] & df_ai['has_ai_category']).sum(),\n",
    "        (~df_ai['mentions_ai'] & ~df_ai['has_ai_category']).sum()\n",
    "    ],\n",
    "    'Percentage': [\n",
    "        100.0,\n",
    "        ai_in_description/total_companies*100,\n",
    "        ai_in_category/total_companies*100,\n",
    "        both_ai/total_companies*100,\n",
    "        either_ai/total_companies*100,\n",
    "        (df_ai['mentions_ai'] & ~df_ai['has_ai_category']).sum()/total_companies*100,\n",
    "        (~df_ai['mentions_ai'] & df_ai['has_ai_category']).sum()/total_companies*100,\n",
    "        (~df_ai['mentions_ai'] & ~df_ai['has_ai_category']).sum()/total_companies*100\n",
    "    ]\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "summary_df.to_csv('ai_mentions_summary.csv', index=False)\n",
    "print(\"=\" * 80)\n",
    "print(\"Summary saved to: ai_mentions_summary.csv\")\n",
    "\n",
    "# Export pattern breakdown\n",
    "pattern_df = pd.DataFrame([\n",
    "    {'Pattern': pattern.replace('_', ' ').title(), 'Count': count, 'Percentage': count/total_companies*100}\n",
    "    for pattern, count in sorted_patterns\n",
    "])\n",
    "pattern_df.to_csv('ai_patterns_breakdown.csv', index=False)\n",
    "print(\"Pattern breakdown saved to: ai_patterns_breakdown.csv\")\n",
    "\n",
    "# Export sector breakdown\n",
    "sector_df = pd.DataFrame(sector_stats)\n",
    "sector_df.to_csv('ai_sector_breakdown.csv', index=False)\n",
    "print(\"Sector breakdown saved to: ai_sector_breakdown.csv\")\n",
    "\n",
    "# Export list of AI companies\n",
    "ai_companies_export = df_ai[df_ai['mentions_ai']][['name', 'short_description', 'categories', 'founded_date']].copy()\n",
    "if 'employees_midpoint' in df_ai.columns:\n",
    "    ai_companies_export['employees_midpoint'] = df_ai[df_ai['mentions_ai']]['employees_midpoint']\n",
    "ai_companies_export = ai_companies_export.sort_values('name')\n",
    "ai_companies_export.to_csv('companies_mentioning_ai.csv', index=False)\n",
    "print(f\"List of {len(ai_companies_export):,} companies mentioning AI saved to: companies_mentioning_ai.csv\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ANALYSIS COMPLETE!\")\n",
    "print(\"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5071057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "AI MENTIONS IN COMPANY DESCRIPTIONS - ANALYSIS SUMMARY\n",
      "================================================================================\n",
      "\n",
      "Generated: 2025-11-15 12:09:32\n",
      "\n",
      "OVERALL STATISTICS\n",
      "--------------------------------------------------------------------------------\n",
      "Total Companies Analyzed: 26,012\n",
      "Companies Mentioning AI in Description: 6,693 (25.73%)\n",
      "Companies with AI Category: 5,036 (19.36%)\n",
      "Companies with Both Description & Category: 3,790\n",
      "Companies with Either Description OR Category: 7,939 (30.52%)\n",
      "Description Only (no AI category): 2,903\n",
      "Category Only (no AI in description): 1,246\n",
      "Neither Description nor Category: 18,073\n",
      "\n",
      "AI TERMINOLOGY BREAKDOWN\n",
      "--------------------------------------------------------------------------------\n",
      "  Ai Direct                     :  6,338 companies (24.37%)\n",
      "  Ai Powered                    :  1,699 companies ( 6.53%)\n",
      "  Artificial Intelligence       :    367 companies ( 1.41%)\n",
      "  Generative Ai                 :    201 companies ( 0.77%)\n",
      "  Machine Learning              :    126 companies ( 0.48%)\n",
      "  Ai Native                     :     81 companies ( 0.31%)\n",
      "  Ai Agent                      :     80 companies ( 0.31%)\n",
      "  Llm                           :     68 companies ( 0.26%)\n",
      "  Computer Vision               :     32 companies ( 0.12%)\n",
      "  Nlp                           :     12 companies ( 0.05%)\n",
      "  Deep Learning                 :      8 companies ( 0.03%)\n",
      "  Neural Network                :      1 companies ( 0.00%)\n",
      "\n",
      "SECTOR-SPECIFIC AI MENTIONS\n",
      "--------------------------------------------------------------------------------\n",
      "Software:\n",
      "  Total Companies: 5,552\n",
      "  Mentioning AI: 2,307 (41.55%)\n",
      "\n",
      "SaaS:\n",
      "  Total Companies: 1,896\n",
      "  Mentioning AI: 824 (43.46%)\n",
      "\n",
      "Health Care:\n",
      "  Total Companies: 1,302\n",
      "  Mentioning AI: 355 (27.27%)\n",
      "\n",
      "FinTech:\n",
      "  Total Companies: 814\n",
      "  Mentioning AI: 198 (24.32%)\n",
      "\n",
      "Blockchain:\n",
      "  Total Companies: 620\n",
      "  Mentioning AI: 118 (19.03%)\n",
      "\n",
      "Robotics:\n",
      "  Total Companies: 234\n",
      "  Mentioning AI: 79 (33.76%)\n",
      "\n",
      "================================================================================\n",
      "Summary saved to: ai_mentions_summary.csv\n",
      "Pattern breakdown saved to: ai_patterns_breakdown.csv\n",
      "Sector breakdown saved to: ai_sector_breakdown.csv\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['founded_date'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 165\u001b[39m\n",
      "\u001b[32m    162\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mSector breakdown saved to: ai_sector_breakdown.csv\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[32m    164\u001b[39m \u001b[38;5;66;03m# Export list of AI companies\u001b[39;00m\n",
      "\u001b[32m--> \u001b[39m\u001b[32m165\u001b[39m ai_companies_export = \u001b[43mdf_ai\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdf_ai\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmentions_ai\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mname\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mshort_description\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcategories\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mfounded_date\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m.copy()\n",
      "\u001b[32m    166\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33memployees_midpoint\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m df_ai.columns:\n",
      "\u001b[32m    167\u001b[39m     ai_companies_export[\u001b[33m'\u001b[39m\u001b[33memployees_midpoint\u001b[39m\u001b[33m'\u001b[39m] = df_ai[df_ai[\u001b[33m'\u001b[39m\u001b[33mmentions_ai\u001b[39m\u001b[33m'\u001b[39m]][\u001b[33m'\u001b[39m\u001b[33memployees_midpoint\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Research/.venv/lib/python3.14/site-packages/pandas/core/frame.py:4119\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n",
      "\u001b[32m   4117\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "\u001b[32m   4118\u001b[39m         key = \u001b[38;5;28mlist\u001b[39m(key)\n",
      "\u001b[32m-> \u001b[39m\u001b[32m4119\u001b[39m     indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumns\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m]\n",
      "\u001b[32m   4121\u001b[39m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n",
      "\u001b[32m   4122\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mbool\u001b[39m:\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Research/.venv/lib/python3.14/site-packages/pandas/core/indexes/base.py:6212\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n",
      "\u001b[32m   6209\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[32m   6210\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n",
      "\u001b[32m-> \u001b[39m\u001b[32m6212\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m   6214\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n",
      "\u001b[32m   6215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n",
      "\u001b[32m   6216\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Research/.venv/lib/python3.14/site-packages/pandas/core/indexes/base.py:6264\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n",
      "\u001b[32m   6261\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[32m   6263\u001b[39m not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n",
      "\u001b[32m-> \u001b[39m\u001b[32m6264\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\n",
      "\u001b[31mKeyError\u001b[39m: \"['founded_date'] not in index\""
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# AI MENTIONS ANALYSIS - FOCUSED ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "def analyze_ai_mentions_focused(df):\n",
    "    \"\"\"Comprehensive analysis of AI mentions in descriptions\"\"\"\n",
    "    \n",
    "    # Define AI-related patterns\n",
    "    ai_patterns = {\n",
    "        'ai_direct': r'\\bai\\b',\n",
    "        'artificial_intelligence': r'\\bartificial intelligence\\b',\n",
    "        'machine_learning': r'\\bmachine learning\\b|\\bml\\b',\n",
    "        'deep_learning': r'\\bdeep learning\\b',\n",
    "        'neural_network': r'\\bneural network\\b',\n",
    "        'llm': r'\\bllm\\b|\\blarge language model\\b',\n",
    "        'generative_ai': r'\\bgenerative ai\\b|\\bgenai\\b',\n",
    "        'computer_vision': r'\\bcomputer vision\\b',\n",
    "        'nlp': r'\\bnlp\\b|\\bnatural language processing\\b',\n",
    "        'ai_powered': r'\\bai.powered\\b|\\bai.driven\\b',\n",
    "        'ai_native': r'\\bai.native\\b',\n",
    "        'ai_agent': r'\\bai agent\\b',\n",
    "    }\n",
    "    \n",
    "    # Check for any AI mention (broad)\n",
    "    broad_ai_pattern = r'\\bai\\b|\\bartificial intelligence\\b|\\bmachine learning\\b|\\bdeep learning\\b|\\bneural\\b|\\bllm\\b|\\bgenerative ai\\b|\\bgenai\\b'\n",
    "    df['mentions_ai'] = df['short_description'].str.contains(broad_ai_pattern, case=False, na=False, regex=True)\n",
    "    \n",
    "    # Check for AI category\n",
    "    df['has_ai_category'] = df['categories'].str.contains('Artificial Intelligence', na=False, case=False)\n",
    "    \n",
    "    # Detailed pattern matching\n",
    "    pattern_counts = {}\n",
    "    for pattern_name, pattern in ai_patterns.items():\n",
    "        mask = df['short_description'].str.contains(pattern, case=False, na=False, regex=True)\n",
    "        pattern_counts[pattern_name] = mask.sum()\n",
    "    \n",
    "    return df, pattern_counts\n",
    "\n",
    "# Run analysis\n",
    "df_ai, pattern_counts = analyze_ai_mentions_focused(df)\n",
    "\n",
    "# Calculate statistics\n",
    "total_companies = len(df_ai)\n",
    "ai_in_description = df_ai['mentions_ai'].sum()\n",
    "ai_in_category = df_ai['has_ai_category'].sum()\n",
    "both_ai = (df_ai['mentions_ai'] & df_ai['has_ai_category']).sum()\n",
    "either_ai = (df_ai['mentions_ai'] | df_ai['has_ai_category']).sum()\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"AI MENTIONS IN COMPANY DESCRIPTIONS - ANALYSIS SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nGenerated: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "\n",
    "print(\"OVERALL STATISTICS\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"Total Companies Analyzed: {total_companies:,}\")\n",
    "print(f\"Companies Mentioning AI in Description: {ai_in_description:,} ({ai_in_description/total_companies*100:.2f}%)\")\n",
    "print(f\"Companies with AI Category: {ai_in_category:,} ({ai_in_category/total_companies*100:.2f}%)\")\n",
    "print(f\"Companies with Both Description & Category: {both_ai:,}\")\n",
    "print(f\"Companies with Either Description OR Category: {either_ai:,} ({either_ai/total_companies*100:.2f}%)\")\n",
    "print(f\"Description Only (no AI category): {(df_ai['mentions_ai'] & ~df_ai['has_ai_category']).sum():,}\")\n",
    "print(f\"Category Only (no AI in description): {(~df_ai['mentions_ai'] & df_ai['has_ai_category']).sum():,}\")\n",
    "print(f\"Neither Description nor Category: {(~df_ai['mentions_ai'] & ~df_ai['has_ai_category']).sum():,}\")\n",
    "\n",
    "print(\"\\nAI TERMINOLOGY BREAKDOWN\")\n",
    "print(\"-\" * 80)\n",
    "sorted_patterns = sorted(pattern_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "for pattern, count in sorted_patterns:\n",
    "    pct = (count / total_companies) * 100\n",
    "    print(f\"  {pattern.replace('_', ' ').title():30s}: {count:6,} companies ({pct:5.2f}%)\")\n",
    "\n",
    "# Company size analysis for AI companies\n",
    "ai_companies = df_ai[df_ai['mentions_ai']]\n",
    "if len(ai_companies) > 0 and 'employees_midpoint' in ai_companies.columns:\n",
    "    print(\"\\nAI COMPANY SIZE ANALYSIS\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"Average Employees (AI Companies): {ai_companies['employees_midpoint'].mean():.1f}\")\n",
    "    print(f\"Median Employees (AI Companies): {ai_companies['employees_midpoint'].median():.1f}\")\n",
    "    print(f\"Small Companies (1-10 employees): {(ai_companies['employees_min'] <= 10).sum():,}\")\n",
    "    print(f\"Medium Companies (11-50 employees): {((ai_companies['employees_min'] > 10) & (ai_companies['employees_max'] <= 50)).sum():,}\")\n",
    "    print(f\"Large Companies (51+ employees): {(ai_companies['employees_min'] > 50).sum():,}\")\n",
    "\n",
    "# Sector analysis\n",
    "print(\"\\nSECTOR-SPECIFIC AI MENTIONS\")\n",
    "print(\"-\" * 80)\n",
    "sectors = {\n",
    "    'Software': df_ai['categories'].str.contains('Software', na=False, case=False),\n",
    "    'SaaS': df_ai['categories'].str.contains('SaaS', na=False, case=False),\n",
    "    'Health Care': df_ai['categories'].str.contains('Health Care', na=False, case=False),\n",
    "    'FinTech': df_ai['categories'].str.contains('FinTech', na=False, case=False),\n",
    "    'Blockchain': df_ai['categories'].str.contains('Blockchain', na=False, case=False),\n",
    "    'Robotics': df_ai['categories'].str.contains('Robotics', na=False, case=False),\n",
    "}\n",
    "\n",
    "sector_stats = []\n",
    "for sector_name, mask in sectors.items():\n",
    "    sector_df = df_ai[mask]\n",
    "    if len(sector_df) > 0:\n",
    "        sector_ai = sector_df['mentions_ai'].sum()\n",
    "        pct_ai = (sector_ai / len(sector_df)) * 100\n",
    "        sector_stats.append({\n",
    "            'Sector': sector_name,\n",
    "            'Total': len(sector_df),\n",
    "            'Mentions AI': sector_ai,\n",
    "            'Percentage': pct_ai\n",
    "        })\n",
    "        print(f\"{sector_name}:\")\n",
    "        print(f\"  Total Companies: {len(sector_df):,}\")\n",
    "        print(f\"  Mentioning AI: {sector_ai:,} ({pct_ai:.2f}%)\")\n",
    "        print()\n",
    "\n",
    "# Export summary to CSV\n",
    "summary_data = {\n",
    "    'Metric': [\n",
    "        'Total Companies',\n",
    "        'Mentions AI in Description',\n",
    "        'Has AI Category',\n",
    "        'Both Description and Category',\n",
    "        'Either Description or Category',\n",
    "        'Description Only',\n",
    "        'Category Only',\n",
    "        'Neither'\n",
    "    ],\n",
    "    'Count': [\n",
    "        total_companies,\n",
    "        ai_in_description,\n",
    "        ai_in_category,\n",
    "        both_ai,\n",
    "        either_ai,\n",
    "        (df_ai['mentions_ai'] & ~df_ai['has_ai_category']).sum(),\n",
    "        (~df_ai['mentions_ai'] & df_ai['has_ai_category']).sum(),\n",
    "        (~df_ai['mentions_ai'] & ~df_ai['has_ai_category']).sum()\n",
    "    ],\n",
    "    'Percentage': [\n",
    "        100.0,\n",
    "        ai_in_description/total_companies*100,\n",
    "        ai_in_category/total_companies*100,\n",
    "        both_ai/total_companies*100,\n",
    "        either_ai/total_companies*100,\n",
    "        (df_ai['mentions_ai'] & ~df_ai['has_ai_category']).sum()/total_companies*100,\n",
    "        (~df_ai['mentions_ai'] & df_ai['has_ai_category']).sum()/total_companies*100,\n",
    "        (~df_ai['mentions_ai'] & ~df_ai['has_ai_category']).sum()/total_companies*100\n",
    "    ]\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "summary_df.to_csv('ai_mentions_summary.csv', index=False)\n",
    "print(\"=\" * 80)\n",
    "print(\"Summary saved to: ai_mentions_summary.csv\")\n",
    "\n",
    "# Export pattern breakdown\n",
    "pattern_df = pd.DataFrame([\n",
    "    {'Pattern': pattern.replace('_', ' ').title(), 'Count': count, 'Percentage': count/total_companies*100}\n",
    "    for pattern, count in sorted_patterns\n",
    "])\n",
    "pattern_df.to_csv('ai_patterns_breakdown.csv', index=False)\n",
    "print(\"Pattern breakdown saved to: ai_patterns_breakdown.csv\")\n",
    "\n",
    "# Export sector breakdown\n",
    "sector_df = pd.DataFrame(sector_stats)\n",
    "sector_df.to_csv('ai_sector_breakdown.csv', index=False)\n",
    "print(\"Sector breakdown saved to: ai_sector_breakdown.csv\")\n",
    "\n",
    "# Export list of AI companies\n",
    "ai_companies_export = df_ai[df_ai['mentions_ai']][['name', 'short_description', 'categories', 'founded_date']].copy()\n",
    "if 'employees_midpoint' in df_ai.columns:\n",
    "    ai_companies_export['employees_midpoint'] = df_ai[df_ai['mentions_ai']]['employees_midpoint']\n",
    "ai_companies_export = ai_companies_export.sort_values('name')\n",
    "ai_companies_export.to_csv('companies_mentioning_ai.csv', index=False)\n",
    "print(f\"List of {len(ai_companies_export):,} companies mentioning AI saved to: companies_mentioning_ai.csv\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ANALYSIS COMPLETE!\")\n",
    "print(\"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c106b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "AI MENTIONS IN COMPANY DESCRIPTIONS - ANALYSIS SUMMARY\n",
      "================================================================================\n",
      "\n",
      "Generated: 2025-11-15 12:09:32\n",
      "\n",
      "OVERALL STATISTICS\n",
      "--------------------------------------------------------------------------------\n",
      "Total Companies Analyzed: 26,012\n",
      "Companies Mentioning AI in Description: 6,693 (25.73%)\n",
      "Companies with AI Category: 5,036 (19.36%)\n",
      "Companies with Both Description & Category: 3,790\n",
      "Companies with Either Description OR Category: 7,939 (30.52%)\n",
      "Description Only (no AI category): 2,903\n",
      "Category Only (no AI in description): 1,246\n",
      "Neither Description nor Category: 18,073\n",
      "\n",
      "AI TERMINOLOGY BREAKDOWN\n",
      "--------------------------------------------------------------------------------\n",
      "  Ai Direct                     :  6,338 companies (24.37%)\n",
      "  Ai Powered                    :  1,699 companies ( 6.53%)\n",
      "  Artificial Intelligence       :    367 companies ( 1.41%)\n",
      "  Generative Ai                 :    201 companies ( 0.77%)\n",
      "  Machine Learning              :    126 companies ( 0.48%)\n",
      "  Ai Native                     :     81 companies ( 0.31%)\n",
      "  Ai Agent                      :     80 companies ( 0.31%)\n",
      "  Llm                           :     68 companies ( 0.26%)\n",
      "  Computer Vision               :     32 companies ( 0.12%)\n",
      "  Nlp                           :     12 companies ( 0.05%)\n",
      "  Deep Learning                 :      8 companies ( 0.03%)\n",
      "  Neural Network                :      1 companies ( 0.00%)\n",
      "\n",
      "SECTOR-SPECIFIC AI MENTIONS\n",
      "--------------------------------------------------------------------------------\n",
      "Software:\n",
      "  Total Companies: 5,552\n",
      "  Mentioning AI: 2,307 (41.55%)\n",
      "\n",
      "SaaS:\n",
      "  Total Companies: 1,896\n",
      "  Mentioning AI: 824 (43.46%)\n",
      "\n",
      "Health Care:\n",
      "  Total Companies: 1,302\n",
      "  Mentioning AI: 355 (27.27%)\n",
      "\n",
      "FinTech:\n",
      "  Total Companies: 814\n",
      "  Mentioning AI: 198 (24.32%)\n",
      "\n",
      "Blockchain:\n",
      "  Total Companies: 620\n",
      "  Mentioning AI: 118 (19.03%)\n",
      "\n",
      "Robotics:\n",
      "  Total Companies: 234\n",
      "  Mentioning AI: 79 (33.76%)\n",
      "\n",
      "================================================================================\n",
      "Summary saved to: ai_mentions_summary.csv\n",
      "Pattern breakdown saved to: ai_patterns_breakdown.csv\n",
      "Sector breakdown saved to: ai_sector_breakdown.csv\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['founded_date'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 165\u001b[39m\n",
      "\u001b[32m    162\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mSector breakdown saved to: ai_sector_breakdown.csv\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[32m    164\u001b[39m \u001b[38;5;66;03m# Export list of AI companies\u001b[39;00m\n",
      "\u001b[32m--> \u001b[39m\u001b[32m165\u001b[39m ai_companies_export = \u001b[43mdf_ai\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdf_ai\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmentions_ai\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mname\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mshort_description\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcategories\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mfounded_date\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m.copy()\n",
      "\u001b[32m    166\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33memployees_midpoint\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m df_ai.columns:\n",
      "\u001b[32m    167\u001b[39m     ai_companies_export[\u001b[33m'\u001b[39m\u001b[33memployees_midpoint\u001b[39m\u001b[33m'\u001b[39m] = df_ai[df_ai[\u001b[33m'\u001b[39m\u001b[33mmentions_ai\u001b[39m\u001b[33m'\u001b[39m]][\u001b[33m'\u001b[39m\u001b[33memployees_midpoint\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Research/.venv/lib/python3.14/site-packages/pandas/core/frame.py:4119\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n",
      "\u001b[32m   4117\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "\u001b[32m   4118\u001b[39m         key = \u001b[38;5;28mlist\u001b[39m(key)\n",
      "\u001b[32m-> \u001b[39m\u001b[32m4119\u001b[39m     indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumns\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m]\n",
      "\u001b[32m   4121\u001b[39m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n",
      "\u001b[32m   4122\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mbool\u001b[39m:\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Research/.venv/lib/python3.14/site-packages/pandas/core/indexes/base.py:6212\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n",
      "\u001b[32m   6209\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[32m   6210\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n",
      "\u001b[32m-> \u001b[39m\u001b[32m6212\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m   6214\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n",
      "\u001b[32m   6215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n",
      "\u001b[32m   6216\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Research/.venv/lib/python3.14/site-packages/pandas/core/indexes/base.py:6264\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n",
      "\u001b[32m   6261\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[32m   6263\u001b[39m not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n",
      "\u001b[32m-> \u001b[39m\u001b[32m6264\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\n",
      "\u001b[31mKeyError\u001b[39m: \"['founded_date'] not in index\""
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# AI MENTIONS ANALYSIS - FOCUSED ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "def analyze_ai_mentions_focused(df):\n",
    "    \"\"\"Comprehensive analysis of AI mentions in descriptions\"\"\"\n",
    "    \n",
    "    # Define AI-related patterns\n",
    "    ai_patterns = {\n",
    "        'ai_direct': r'\\bai\\b',\n",
    "        'artificial_intelligence': r'\\bartificial intelligence\\b',\n",
    "        'machine_learning': r'\\bmachine learning\\b|\\bml\\b',\n",
    "        'deep_learning': r'\\bdeep learning\\b',\n",
    "        'neural_network': r'\\bneural network\\b',\n",
    "        'llm': r'\\bllm\\b|\\blarge language model\\b',\n",
    "        'generative_ai': r'\\bgenerative ai\\b|\\bgenai\\b',\n",
    "        'computer_vision': r'\\bcomputer vision\\b',\n",
    "        'nlp': r'\\bnlp\\b|\\bnatural language processing\\b',\n",
    "        'ai_powered': r'\\bai.powered\\b|\\bai.driven\\b',\n",
    "        'ai_native': r'\\bai.native\\b',\n",
    "        'ai_agent': r'\\bai agent\\b',\n",
    "    }\n",
    "    \n",
    "    # Check for any AI mention (broad)\n",
    "    broad_ai_pattern = r'\\bai\\b|\\bartificial intelligence\\b|\\bmachine learning\\b|\\bdeep learning\\b|\\bneural\\b|\\bllm\\b|\\bgenerative ai\\b|\\bgenai\\b'\n",
    "    df['mentions_ai'] = df['short_description'].str.contains(broad_ai_pattern, case=False, na=False, regex=True)\n",
    "    \n",
    "    # Check for AI category\n",
    "    df['has_ai_category'] = df['categories'].str.contains('Artificial Intelligence', na=False, case=False)\n",
    "    \n",
    "    # Detailed pattern matching\n",
    "    pattern_counts = {}\n",
    "    for pattern_name, pattern in ai_patterns.items():\n",
    "        mask = df['short_description'].str.contains(pattern, case=False, na=False, regex=True)\n",
    "        pattern_counts[pattern_name] = mask.sum()\n",
    "    \n",
    "    return df, pattern_counts\n",
    "\n",
    "# Run analysis\n",
    "df_ai, pattern_counts = analyze_ai_mentions_focused(df)\n",
    "\n",
    "# Calculate statistics\n",
    "total_companies = len(df_ai)\n",
    "ai_in_description = df_ai['mentions_ai'].sum()\n",
    "ai_in_category = df_ai['has_ai_category'].sum()\n",
    "both_ai = (df_ai['mentions_ai'] & df_ai['has_ai_category']).sum()\n",
    "either_ai = (df_ai['mentions_ai'] | df_ai['has_ai_category']).sum()\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"AI MENTIONS IN COMPANY DESCRIPTIONS - ANALYSIS SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nGenerated: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "\n",
    "print(\"OVERALL STATISTICS\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"Total Companies Analyzed: {total_companies:,}\")\n",
    "print(f\"Companies Mentioning AI in Description: {ai_in_description:,} ({ai_in_description/total_companies*100:.2f}%)\")\n",
    "print(f\"Companies with AI Category: {ai_in_category:,} ({ai_in_category/total_companies*100:.2f}%)\")\n",
    "print(f\"Companies with Both Description & Category: {both_ai:,}\")\n",
    "print(f\"Companies with Either Description OR Category: {either_ai:,} ({either_ai/total_companies*100:.2f}%)\")\n",
    "print(f\"Description Only (no AI category): {(df_ai['mentions_ai'] & ~df_ai['has_ai_category']).sum():,}\")\n",
    "print(f\"Category Only (no AI in description): {(~df_ai['mentions_ai'] & df_ai['has_ai_category']).sum():,}\")\n",
    "print(f\"Neither Description nor Category: {(~df_ai['mentions_ai'] & ~df_ai['has_ai_category']).sum():,}\")\n",
    "\n",
    "print(\"\\nAI TERMINOLOGY BREAKDOWN\")\n",
    "print(\"-\" * 80)\n",
    "sorted_patterns = sorted(pattern_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "for pattern, count in sorted_patterns:\n",
    "    pct = (count / total_companies) * 100\n",
    "    print(f\"  {pattern.replace('_', ' ').title():30s}: {count:6,} companies ({pct:5.2f}%)\")\n",
    "\n",
    "# Company size analysis for AI companies\n",
    "ai_companies = df_ai[df_ai['mentions_ai']]\n",
    "if len(ai_companies) > 0 and 'employees_midpoint' in ai_companies.columns:\n",
    "    print(\"\\nAI COMPANY SIZE ANALYSIS\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"Average Employees (AI Companies): {ai_companies['employees_midpoint'].mean():.1f}\")\n",
    "    print(f\"Median Employees (AI Companies): {ai_companies['employees_midpoint'].median():.1f}\")\n",
    "    print(f\"Small Companies (1-10 employees): {(ai_companies['employees_min'] <= 10).sum():,}\")\n",
    "    print(f\"Medium Companies (11-50 employees): {((ai_companies['employees_min'] > 10) & (ai_companies['employees_max'] <= 50)).sum():,}\")\n",
    "    print(f\"Large Companies (51+ employees): {(ai_companies['employees_min'] > 50).sum():,}\")\n",
    "\n",
    "# Sector analysis\n",
    "print(\"\\nSECTOR-SPECIFIC AI MENTIONS\")\n",
    "print(\"-\" * 80)\n",
    "sectors = {\n",
    "    'Software': df_ai['categories'].str.contains('Software', na=False, case=False),\n",
    "    'SaaS': df_ai['categories'].str.contains('SaaS', na=False, case=False),\n",
    "    'Health Care': df_ai['categories'].str.contains('Health Care', na=False, case=False),\n",
    "    'FinTech': df_ai['categories'].str.contains('FinTech', na=False, case=False),\n",
    "    'Blockchain': df_ai['categories'].str.contains('Blockchain', na=False, case=False),\n",
    "    'Robotics': df_ai['categories'].str.contains('Robotics', na=False, case=False),\n",
    "}\n",
    "\n",
    "sector_stats = []\n",
    "for sector_name, mask in sectors.items():\n",
    "    sector_df = df_ai[mask]\n",
    "    if len(sector_df) > 0:\n",
    "        sector_ai = sector_df['mentions_ai'].sum()\n",
    "        pct_ai = (sector_ai / len(sector_df)) * 100\n",
    "        sector_stats.append({\n",
    "            'Sector': sector_name,\n",
    "            'Total': len(sector_df),\n",
    "            'Mentions AI': sector_ai,\n",
    "            'Percentage': pct_ai\n",
    "        })\n",
    "        print(f\"{sector_name}:\")\n",
    "        print(f\"  Total Companies: {len(sector_df):,}\")\n",
    "        print(f\"  Mentioning AI: {sector_ai:,} ({pct_ai:.2f}%)\")\n",
    "        print()\n",
    "\n",
    "# Export summary to CSV\n",
    "summary_data = {\n",
    "    'Metric': [\n",
    "        'Total Companies',\n",
    "        'Mentions AI in Description',\n",
    "        'Has AI Category',\n",
    "        'Both Description and Category',\n",
    "        'Either Description or Category',\n",
    "        'Description Only',\n",
    "        'Category Only',\n",
    "        'Neither'\n",
    "    ],\n",
    "    'Count': [\n",
    "        total_companies,\n",
    "        ai_in_description,\n",
    "        ai_in_category,\n",
    "        both_ai,\n",
    "        either_ai,\n",
    "        (df_ai['mentions_ai'] & ~df_ai['has_ai_category']).sum(),\n",
    "        (~df_ai['mentions_ai'] & df_ai['has_ai_category']).sum(),\n",
    "        (~df_ai['mentions_ai'] & ~df_ai['has_ai_category']).sum()\n",
    "    ],\n",
    "    'Percentage': [\n",
    "        100.0,\n",
    "        ai_in_description/total_companies*100,\n",
    "        ai_in_category/total_companies*100,\n",
    "        both_ai/total_companies*100,\n",
    "        either_ai/total_companies*100,\n",
    "        (df_ai['mentions_ai'] & ~df_ai['has_ai_category']).sum()/total_companies*100,\n",
    "        (~df_ai['mentions_ai'] & df_ai['has_ai_category']).sum()/total_companies*100,\n",
    "        (~df_ai['mentions_ai'] & ~df_ai['has_ai_category']).sum()/total_companies*100\n",
    "    ]\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "summary_df.to_csv('ai_mentions_summary.csv', index=False)\n",
    "print(\"=\" * 80)\n",
    "print(\"Summary saved to: ai_mentions_summary.csv\")\n",
    "\n",
    "# Export pattern breakdown\n",
    "pattern_df = pd.DataFrame([\n",
    "    {'Pattern': pattern.replace('_', ' ').title(), 'Count': count, 'Percentage': count/total_companies*100}\n",
    "    for pattern, count in sorted_patterns\n",
    "])\n",
    "pattern_df.to_csv('ai_patterns_breakdown.csv', index=False)\n",
    "print(\"Pattern breakdown saved to: ai_patterns_breakdown.csv\")\n",
    "\n",
    "# Export sector breakdown\n",
    "sector_df = pd.DataFrame(sector_stats)\n",
    "sector_df.to_csv('ai_sector_breakdown.csv', index=False)\n",
    "print(\"Sector breakdown saved to: ai_sector_breakdown.csv\")\n",
    "\n",
    "# Export list of AI companies\n",
    "ai_companies_export = df_ai[df_ai['mentions_ai']][['name', 'short_description', 'categories', 'founded_date']].copy()\n",
    "if 'employees_midpoint' in df_ai.columns:\n",
    "    ai_companies_export['employees_midpoint'] = df_ai[df_ai['mentions_ai']]['employees_midpoint']\n",
    "ai_companies_export = ai_companies_export.sort_values('name')\n",
    "ai_companies_export.to_csv('companies_mentioning_ai.csv', index=False)\n",
    "print(f\"List of {len(ai_companies_export):,} companies mentioning AI saved to: companies_mentioning_ai.csv\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ANALYSIS COMPLETE!\")\n",
    "print(\"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f56bb36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "AI MENTIONS IN COMPANY DESCRIPTIONS - ANALYSIS SUMMARY\n",
      "================================================================================\n",
      "\n",
      "Generated: 2025-11-15 12:09:32\n",
      "\n",
      "OVERALL STATISTICS\n",
      "--------------------------------------------------------------------------------\n",
      "Total Companies Analyzed: 26,012\n",
      "Companies Mentioning AI in Description: 6,693 (25.73%)\n",
      "Companies with AI Category: 5,036 (19.36%)\n",
      "Companies with Both Description & Category: 3,790\n",
      "Companies with Either Description OR Category: 7,939 (30.52%)\n",
      "Description Only (no AI category): 2,903\n",
      "Category Only (no AI in description): 1,246\n",
      "Neither Description nor Category: 18,073\n",
      "\n",
      "AI TERMINOLOGY BREAKDOWN\n",
      "--------------------------------------------------------------------------------\n",
      "  Ai Direct                     :  6,338 companies (24.37%)\n",
      "  Ai Powered                    :  1,699 companies ( 6.53%)\n",
      "  Artificial Intelligence       :    367 companies ( 1.41%)\n",
      "  Generative Ai                 :    201 companies ( 0.77%)\n",
      "  Machine Learning              :    126 companies ( 0.48%)\n",
      "  Ai Native                     :     81 companies ( 0.31%)\n",
      "  Ai Agent                      :     80 companies ( 0.31%)\n",
      "  Llm                           :     68 companies ( 0.26%)\n",
      "  Computer Vision               :     32 companies ( 0.12%)\n",
      "  Nlp                           :     12 companies ( 0.05%)\n",
      "  Deep Learning                 :      8 companies ( 0.03%)\n",
      "  Neural Network                :      1 companies ( 0.00%)\n",
      "\n",
      "SECTOR-SPECIFIC AI MENTIONS\n",
      "--------------------------------------------------------------------------------\n",
      "Software:\n",
      "  Total Companies: 5,552\n",
      "  Mentioning AI: 2,307 (41.55%)\n",
      "\n",
      "SaaS:\n",
      "  Total Companies: 1,896\n",
      "  Mentioning AI: 824 (43.46%)\n",
      "\n",
      "Health Care:\n",
      "  Total Companies: 1,302\n",
      "  Mentioning AI: 355 (27.27%)\n",
      "\n",
      "FinTech:\n",
      "  Total Companies: 814\n",
      "  Mentioning AI: 198 (24.32%)\n",
      "\n",
      "Blockchain:\n",
      "  Total Companies: 620\n",
      "  Mentioning AI: 118 (19.03%)\n",
      "\n",
      "Robotics:\n",
      "  Total Companies: 234\n",
      "  Mentioning AI: 79 (33.76%)\n",
      "\n",
      "================================================================================\n",
      "Summary saved to: ai_mentions_summary.csv\n",
      "Pattern breakdown saved to: ai_patterns_breakdown.csv\n",
      "Sector breakdown saved to: ai_sector_breakdown.csv\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['founded_date'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 165\u001b[39m\n",
      "\u001b[32m    162\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mSector breakdown saved to: ai_sector_breakdown.csv\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[32m    164\u001b[39m \u001b[38;5;66;03m# Export list of AI companies\u001b[39;00m\n",
      "\u001b[32m--> \u001b[39m\u001b[32m165\u001b[39m ai_companies_export = \u001b[43mdf_ai\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdf_ai\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmentions_ai\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mname\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mshort_description\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcategories\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mfounded_date\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m.copy()\n",
      "\u001b[32m    166\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33memployees_midpoint\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m df_ai.columns:\n",
      "\u001b[32m    167\u001b[39m     ai_companies_export[\u001b[33m'\u001b[39m\u001b[33memployees_midpoint\u001b[39m\u001b[33m'\u001b[39m] = df_ai[df_ai[\u001b[33m'\u001b[39m\u001b[33mmentions_ai\u001b[39m\u001b[33m'\u001b[39m]][\u001b[33m'\u001b[39m\u001b[33memployees_midpoint\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Research/.venv/lib/python3.14/site-packages/pandas/core/frame.py:4119\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n",
      "\u001b[32m   4117\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "\u001b[32m   4118\u001b[39m         key = \u001b[38;5;28mlist\u001b[39m(key)\n",
      "\u001b[32m-> \u001b[39m\u001b[32m4119\u001b[39m     indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumns\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m]\n",
      "\u001b[32m   4121\u001b[39m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n",
      "\u001b[32m   4122\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mbool\u001b[39m:\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Research/.venv/lib/python3.14/site-packages/pandas/core/indexes/base.py:6212\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n",
      "\u001b[32m   6209\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[32m   6210\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n",
      "\u001b[32m-> \u001b[39m\u001b[32m6212\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m   6214\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n",
      "\u001b[32m   6215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n",
      "\u001b[32m   6216\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Research/.venv/lib/python3.14/site-packages/pandas/core/indexes/base.py:6264\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n",
      "\u001b[32m   6261\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[32m   6263\u001b[39m not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n",
      "\u001b[32m-> \u001b[39m\u001b[32m6264\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\n",
      "\u001b[31mKeyError\u001b[39m: \"['founded_date'] not in index\""
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# AI MENTIONS ANALYSIS - FOCUSED ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "def analyze_ai_mentions_focused(df):\n",
    "    \"\"\"Comprehensive analysis of AI mentions in descriptions\"\"\"\n",
    "    \n",
    "    # Define AI-related patterns\n",
    "    ai_patterns = {\n",
    "        'ai_direct': r'\\bai\\b',\n",
    "        'artificial_intelligence': r'\\bartificial intelligence\\b',\n",
    "        'machine_learning': r'\\bmachine learning\\b|\\bml\\b',\n",
    "        'deep_learning': r'\\bdeep learning\\b',\n",
    "        'neural_network': r'\\bneural network\\b',\n",
    "        'llm': r'\\bllm\\b|\\blarge language model\\b',\n",
    "        'generative_ai': r'\\bgenerative ai\\b|\\bgenai\\b',\n",
    "        'computer_vision': r'\\bcomputer vision\\b',\n",
    "        'nlp': r'\\bnlp\\b|\\bnatural language processing\\b',\n",
    "        'ai_powered': r'\\bai.powered\\b|\\bai.driven\\b',\n",
    "        'ai_native': r'\\bai.native\\b',\n",
    "        'ai_agent': r'\\bai agent\\b',\n",
    "    }\n",
    "    \n",
    "    # Check for any AI mention (broad)\n",
    "    broad_ai_pattern = r'\\bai\\b|\\bartificial intelligence\\b|\\bmachine learning\\b|\\bdeep learning\\b|\\bneural\\b|\\bllm\\b|\\bgenerative ai\\b|\\bgenai\\b'\n",
    "    df['mentions_ai'] = df['short_description'].str.contains(broad_ai_pattern, case=False, na=False, regex=True)\n",
    "    \n",
    "    # Check for AI category\n",
    "    df['has_ai_category'] = df['categories'].str.contains('Artificial Intelligence', na=False, case=False)\n",
    "    \n",
    "    # Detailed pattern matching\n",
    "    pattern_counts = {}\n",
    "    for pattern_name, pattern in ai_patterns.items():\n",
    "        mask = df['short_description'].str.contains(pattern, case=False, na=False, regex=True)\n",
    "        pattern_counts[pattern_name] = mask.sum()\n",
    "    \n",
    "    return df, pattern_counts\n",
    "\n",
    "# Run analysis\n",
    "df_ai, pattern_counts = analyze_ai_mentions_focused(df)\n",
    "\n",
    "# Calculate statistics\n",
    "total_companies = len(df_ai)\n",
    "ai_in_description = df_ai['mentions_ai'].sum()\n",
    "ai_in_category = df_ai['has_ai_category'].sum()\n",
    "both_ai = (df_ai['mentions_ai'] & df_ai['has_ai_category']).sum()\n",
    "either_ai = (df_ai['mentions_ai'] | df_ai['has_ai_category']).sum()\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"AI MENTIONS IN COMPANY DESCRIPTIONS - ANALYSIS SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nGenerated: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "\n",
    "print(\"OVERALL STATISTICS\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"Total Companies Analyzed: {total_companies:,}\")\n",
    "print(f\"Companies Mentioning AI in Description: {ai_in_description:,} ({ai_in_description/total_companies*100:.2f}%)\")\n",
    "print(f\"Companies with AI Category: {ai_in_category:,} ({ai_in_category/total_companies*100:.2f}%)\")\n",
    "print(f\"Companies with Both Description & Category: {both_ai:,}\")\n",
    "print(f\"Companies with Either Description OR Category: {either_ai:,} ({either_ai/total_companies*100:.2f}%)\")\n",
    "print(f\"Description Only (no AI category): {(df_ai['mentions_ai'] & ~df_ai['has_ai_category']).sum():,}\")\n",
    "print(f\"Category Only (no AI in description): {(~df_ai['mentions_ai'] & df_ai['has_ai_category']).sum():,}\")\n",
    "print(f\"Neither Description nor Category: {(~df_ai['mentions_ai'] & ~df_ai['has_ai_category']).sum():,}\")\n",
    "\n",
    "print(\"\\nAI TERMINOLOGY BREAKDOWN\")\n",
    "print(\"-\" * 80)\n",
    "sorted_patterns = sorted(pattern_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "for pattern, count in sorted_patterns:\n",
    "    pct = (count / total_companies) * 100\n",
    "    print(f\"  {pattern.replace('_', ' ').title():30s}: {count:6,} companies ({pct:5.2f}%)\")\n",
    "\n",
    "# Company size analysis for AI companies\n",
    "ai_companies = df_ai[df_ai['mentions_ai']]\n",
    "if len(ai_companies) > 0 and 'employees_midpoint' in ai_companies.columns:\n",
    "    print(\"\\nAI COMPANY SIZE ANALYSIS\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"Average Employees (AI Companies): {ai_companies['employees_midpoint'].mean():.1f}\")\n",
    "    print(f\"Median Employees (AI Companies): {ai_companies['employees_midpoint'].median():.1f}\")\n",
    "    print(f\"Small Companies (1-10 employees): {(ai_companies['employees_min'] <= 10).sum():,}\")\n",
    "    print(f\"Medium Companies (11-50 employees): {((ai_companies['employees_min'] > 10) & (ai_companies['employees_max'] <= 50)).sum():,}\")\n",
    "    print(f\"Large Companies (51+ employees): {(ai_companies['employees_min'] > 50).sum():,}\")\n",
    "\n",
    "# Sector analysis\n",
    "print(\"\\nSECTOR-SPECIFIC AI MENTIONS\")\n",
    "print(\"-\" * 80)\n",
    "sectors = {\n",
    "    'Software': df_ai['categories'].str.contains('Software', na=False, case=False),\n",
    "    'SaaS': df_ai['categories'].str.contains('SaaS', na=False, case=False),\n",
    "    'Health Care': df_ai['categories'].str.contains('Health Care', na=False, case=False),\n",
    "    'FinTech': df_ai['categories'].str.contains('FinTech', na=False, case=False),\n",
    "    'Blockchain': df_ai['categories'].str.contains('Blockchain', na=False, case=False),\n",
    "    'Robotics': df_ai['categories'].str.contains('Robotics', na=False, case=False),\n",
    "}\n",
    "\n",
    "sector_stats = []\n",
    "for sector_name, mask in sectors.items():\n",
    "    sector_df = df_ai[mask]\n",
    "    if len(sector_df) > 0:\n",
    "        sector_ai = sector_df['mentions_ai'].sum()\n",
    "        pct_ai = (sector_ai / len(sector_df)) * 100\n",
    "        sector_stats.append({\n",
    "            'Sector': sector_name,\n",
    "            'Total': len(sector_df),\n",
    "            'Mentions AI': sector_ai,\n",
    "            'Percentage': pct_ai\n",
    "        })\n",
    "        print(f\"{sector_name}:\")\n",
    "        print(f\"  Total Companies: {len(sector_df):,}\")\n",
    "        print(f\"  Mentioning AI: {sector_ai:,} ({pct_ai:.2f}%)\")\n",
    "        print()\n",
    "\n",
    "# Export summary to CSV\n",
    "summary_data = {\n",
    "    'Metric': [\n",
    "        'Total Companies',\n",
    "        'Mentions AI in Description',\n",
    "        'Has AI Category',\n",
    "        'Both Description and Category',\n",
    "        'Either Description or Category',\n",
    "        'Description Only',\n",
    "        'Category Only',\n",
    "        'Neither'\n",
    "    ],\n",
    "    'Count': [\n",
    "        total_companies,\n",
    "        ai_in_description,\n",
    "        ai_in_category,\n",
    "        both_ai,\n",
    "        either_ai,\n",
    "        (df_ai['mentions_ai'] & ~df_ai['has_ai_category']).sum(),\n",
    "        (~df_ai['mentions_ai'] & df_ai['has_ai_category']).sum(),\n",
    "        (~df_ai['mentions_ai'] & ~df_ai['has_ai_category']).sum()\n",
    "    ],\n",
    "    'Percentage': [\n",
    "        100.0,\n",
    "        ai_in_description/total_companies*100,\n",
    "        ai_in_category/total_companies*100,\n",
    "        both_ai/total_companies*100,\n",
    "        either_ai/total_companies*100,\n",
    "        (df_ai['mentions_ai'] & ~df_ai['has_ai_category']).sum()/total_companies*100,\n",
    "        (~df_ai['mentions_ai'] & df_ai['has_ai_category']).sum()/total_companies*100,\n",
    "        (~df_ai['mentions_ai'] & ~df_ai['has_ai_category']).sum()/total_companies*100\n",
    "    ]\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "summary_df.to_csv('ai_mentions_summary.csv', index=False)\n",
    "print(\"=\" * 80)\n",
    "print(\"Summary saved to: ai_mentions_summary.csv\")\n",
    "\n",
    "# Export pattern breakdown\n",
    "pattern_df = pd.DataFrame([\n",
    "    {'Pattern': pattern.replace('_', ' ').title(), 'Count': count, 'Percentage': count/total_companies*100}\n",
    "    for pattern, count in sorted_patterns\n",
    "])\n",
    "pattern_df.to_csv('ai_patterns_breakdown.csv', index=False)\n",
    "print(\"Pattern breakdown saved to: ai_patterns_breakdown.csv\")\n",
    "\n",
    "# Export sector breakdown\n",
    "sector_df = pd.DataFrame(sector_stats)\n",
    "sector_df.to_csv('ai_sector_breakdown.csv', index=False)\n",
    "print(\"Sector breakdown saved to: ai_sector_breakdown.csv\")\n",
    "\n",
    "# Export list of AI companies\n",
    "ai_companies_export = df_ai[df_ai['mentions_ai']][['name', 'short_description', 'categories', 'founded_date']].copy()\n",
    "if 'employees_midpoint' in df_ai.columns:\n",
    "    ai_companies_export['employees_midpoint'] = df_ai[df_ai['mentions_ai']]['employees_midpoint']\n",
    "ai_companies_export = ai_companies_export.sort_values('name')\n",
    "ai_companies_export.to_csv('companies_mentioning_ai.csv', index=False)\n",
    "print(f\"List of {len(ai_companies_export):,} companies mentioning AI saved to: companies_mentioning_ai.csv\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ANALYSIS COMPLETE!\")\n",
    "print(\"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c0daa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "AI MENTIONS IN COMPANY DESCRIPTIONS - ANALYSIS SUMMARY\n",
      "================================================================================\n",
      "\n",
      "Generated: 2025-11-15 12:09:32\n",
      "\n",
      "OVERALL STATISTICS\n",
      "--------------------------------------------------------------------------------\n",
      "Total Companies Analyzed: 26,012\n",
      "Companies Mentioning AI in Description: 6,693 (25.73%)\n",
      "Companies with AI Category: 5,036 (19.36%)\n",
      "Companies with Both Description & Category: 3,790\n",
      "Companies with Either Description OR Category: 7,939 (30.52%)\n",
      "Description Only (no AI category): 2,903\n",
      "Category Only (no AI in description): 1,246\n",
      "Neither Description nor Category: 18,073\n",
      "\n",
      "AI TERMINOLOGY BREAKDOWN\n",
      "--------------------------------------------------------------------------------\n",
      "  Ai Direct                     :  6,338 companies (24.37%)\n",
      "  Ai Powered                    :  1,699 companies ( 6.53%)\n",
      "  Artificial Intelligence       :    367 companies ( 1.41%)\n",
      "  Generative Ai                 :    201 companies ( 0.77%)\n",
      "  Machine Learning              :    126 companies ( 0.48%)\n",
      "  Ai Native                     :     81 companies ( 0.31%)\n",
      "  Ai Agent                      :     80 companies ( 0.31%)\n",
      "  Llm                           :     68 companies ( 0.26%)\n",
      "  Computer Vision               :     32 companies ( 0.12%)\n",
      "  Nlp                           :     12 companies ( 0.05%)\n",
      "  Deep Learning                 :      8 companies ( 0.03%)\n",
      "  Neural Network                :      1 companies ( 0.00%)\n",
      "\n",
      "SECTOR-SPECIFIC AI MENTIONS\n",
      "--------------------------------------------------------------------------------\n",
      "Software:\n",
      "  Total Companies: 5,552\n",
      "  Mentioning AI: 2,307 (41.55%)\n",
      "\n",
      "SaaS:\n",
      "  Total Companies: 1,896\n",
      "  Mentioning AI: 824 (43.46%)\n",
      "\n",
      "Health Care:\n",
      "  Total Companies: 1,302\n",
      "  Mentioning AI: 355 (27.27%)\n",
      "\n",
      "FinTech:\n",
      "  Total Companies: 814\n",
      "  Mentioning AI: 198 (24.32%)\n",
      "\n",
      "Blockchain:\n",
      "  Total Companies: 620\n",
      "  Mentioning AI: 118 (19.03%)\n",
      "\n",
      "Robotics:\n",
      "  Total Companies: 234\n",
      "  Mentioning AI: 79 (33.76%)\n",
      "\n",
      "================================================================================\n",
      "Summary saved to: ai_mentions_summary.csv\n",
      "Pattern breakdown saved to: ai_patterns_breakdown.csv\n",
      "Sector breakdown saved to: ai_sector_breakdown.csv\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['founded_date'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 165\u001b[39m\n",
      "\u001b[32m    162\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mSector breakdown saved to: ai_sector_breakdown.csv\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[32m    164\u001b[39m \u001b[38;5;66;03m# Export list of AI companies\u001b[39;00m\n",
      "\u001b[32m--> \u001b[39m\u001b[32m165\u001b[39m ai_companies_export = \u001b[43mdf_ai\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdf_ai\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmentions_ai\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mname\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mshort_description\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcategories\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mfounded_date\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m.copy()\n",
      "\u001b[32m    166\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33memployees_midpoint\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m df_ai.columns:\n",
      "\u001b[32m    167\u001b[39m     ai_companies_export[\u001b[33m'\u001b[39m\u001b[33memployees_midpoint\u001b[39m\u001b[33m'\u001b[39m] = df_ai[df_ai[\u001b[33m'\u001b[39m\u001b[33mmentions_ai\u001b[39m\u001b[33m'\u001b[39m]][\u001b[33m'\u001b[39m\u001b[33memployees_midpoint\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Research/.venv/lib/python3.14/site-packages/pandas/core/frame.py:4119\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n",
      "\u001b[32m   4117\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "\u001b[32m   4118\u001b[39m         key = \u001b[38;5;28mlist\u001b[39m(key)\n",
      "\u001b[32m-> \u001b[39m\u001b[32m4119\u001b[39m     indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumns\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m]\n",
      "\u001b[32m   4121\u001b[39m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n",
      "\u001b[32m   4122\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mbool\u001b[39m:\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Research/.venv/lib/python3.14/site-packages/pandas/core/indexes/base.py:6212\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n",
      "\u001b[32m   6209\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[32m   6210\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n",
      "\u001b[32m-> \u001b[39m\u001b[32m6212\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m   6214\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n",
      "\u001b[32m   6215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n",
      "\u001b[32m   6216\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Research/.venv/lib/python3.14/site-packages/pandas/core/indexes/base.py:6264\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n",
      "\u001b[32m   6261\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[32m   6263\u001b[39m not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n",
      "\u001b[32m-> \u001b[39m\u001b[32m6264\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\n",
      "\u001b[31mKeyError\u001b[39m: \"['founded_date'] not in index\""
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# AI MENTIONS ANALYSIS - FOCUSED ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "def analyze_ai_mentions_focused(df):\n",
    "    \"\"\"Comprehensive analysis of AI mentions in descriptions\"\"\"\n",
    "    \n",
    "    # Define AI-related patterns\n",
    "    ai_patterns = {\n",
    "        'ai_direct': r'\\bai\\b',\n",
    "        'artificial_intelligence': r'\\bartificial intelligence\\b',\n",
    "        'machine_learning': r'\\bmachine learning\\b|\\bml\\b',\n",
    "        'deep_learning': r'\\bdeep learning\\b',\n",
    "        'neural_network': r'\\bneural network\\b',\n",
    "        'llm': r'\\bllm\\b|\\blarge language model\\b',\n",
    "        'generative_ai': r'\\bgenerative ai\\b|\\bgenai\\b',\n",
    "        'computer_vision': r'\\bcomputer vision\\b',\n",
    "        'nlp': r'\\bnlp\\b|\\bnatural language processing\\b',\n",
    "        'ai_powered': r'\\bai.powered\\b|\\bai.driven\\b',\n",
    "        'ai_native': r'\\bai.native\\b',\n",
    "        'ai_agent': r'\\bai agent\\b',\n",
    "    }\n",
    "    \n",
    "    # Check for any AI mention (broad)\n",
    "    broad_ai_pattern = r'\\bai\\b|\\bartificial intelligence\\b|\\bmachine learning\\b|\\bdeep learning\\b|\\bneural\\b|\\bllm\\b|\\bgenerative ai\\b|\\bgenai\\b'\n",
    "    df['mentions_ai'] = df['short_description'].str.contains(broad_ai_pattern, case=False, na=False, regex=True)\n",
    "    \n",
    "    # Check for AI category\n",
    "    df['has_ai_category'] = df['categories'].str.contains('Artificial Intelligence', na=False, case=False)\n",
    "    \n",
    "    # Detailed pattern matching\n",
    "    pattern_counts = {}\n",
    "    for pattern_name, pattern in ai_patterns.items():\n",
    "        mask = df['short_description'].str.contains(pattern, case=False, na=False, regex=True)\n",
    "        pattern_counts[pattern_name] = mask.sum()\n",
    "    \n",
    "    return df, pattern_counts\n",
    "\n",
    "# Run analysis\n",
    "df_ai, pattern_counts = analyze_ai_mentions_focused(df)\n",
    "\n",
    "# Calculate statistics\n",
    "total_companies = len(df_ai)\n",
    "ai_in_description = df_ai['mentions_ai'].sum()\n",
    "ai_in_category = df_ai['has_ai_category'].sum()\n",
    "both_ai = (df_ai['mentions_ai'] & df_ai['has_ai_category']).sum()\n",
    "either_ai = (df_ai['mentions_ai'] | df_ai['has_ai_category']).sum()\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"AI MENTIONS IN COMPANY DESCRIPTIONS - ANALYSIS SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nGenerated: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "\n",
    "print(\"OVERALL STATISTICS\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"Total Companies Analyzed: {total_companies:,}\")\n",
    "print(f\"Companies Mentioning AI in Description: {ai_in_description:,} ({ai_in_description/total_companies*100:.2f}%)\")\n",
    "print(f\"Companies with AI Category: {ai_in_category:,} ({ai_in_category/total_companies*100:.2f}%)\")\n",
    "print(f\"Companies with Both Description & Category: {both_ai:,}\")\n",
    "print(f\"Companies with Either Description OR Category: {either_ai:,} ({either_ai/total_companies*100:.2f}%)\")\n",
    "print(f\"Description Only (no AI category): {(df_ai['mentions_ai'] & ~df_ai['has_ai_category']).sum():,}\")\n",
    "print(f\"Category Only (no AI in description): {(~df_ai['mentions_ai'] & df_ai['has_ai_category']).sum():,}\")\n",
    "print(f\"Neither Description nor Category: {(~df_ai['mentions_ai'] & ~df_ai['has_ai_category']).sum():,}\")\n",
    "\n",
    "print(\"\\nAI TERMINOLOGY BREAKDOWN\")\n",
    "print(\"-\" * 80)\n",
    "sorted_patterns = sorted(pattern_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "for pattern, count in sorted_patterns:\n",
    "    pct = (count / total_companies) * 100\n",
    "    print(f\"  {pattern.replace('_', ' ').title():30s}: {count:6,} companies ({pct:5.2f}%)\")\n",
    "\n",
    "# Company size analysis for AI companies\n",
    "ai_companies = df_ai[df_ai['mentions_ai']]\n",
    "if len(ai_companies) > 0 and 'employees_midpoint' in ai_companies.columns:\n",
    "    print(\"\\nAI COMPANY SIZE ANALYSIS\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"Average Employees (AI Companies): {ai_companies['employees_midpoint'].mean():.1f}\")\n",
    "    print(f\"Median Employees (AI Companies): {ai_companies['employees_midpoint'].median():.1f}\")\n",
    "    print(f\"Small Companies (1-10 employees): {(ai_companies['employees_min'] <= 10).sum():,}\")\n",
    "    print(f\"Medium Companies (11-50 employees): {((ai_companies['employees_min'] > 10) & (ai_companies['employees_max'] <= 50)).sum():,}\")\n",
    "    print(f\"Large Companies (51+ employees): {(ai_companies['employees_min'] > 50).sum():,}\")\n",
    "\n",
    "# Sector analysis\n",
    "print(\"\\nSECTOR-SPECIFIC AI MENTIONS\")\n",
    "print(\"-\" * 80)\n",
    "sectors = {\n",
    "    'Software': df_ai['categories'].str.contains('Software', na=False, case=False),\n",
    "    'SaaS': df_ai['categories'].str.contains('SaaS', na=False, case=False),\n",
    "    'Health Care': df_ai['categories'].str.contains('Health Care', na=False, case=False),\n",
    "    'FinTech': df_ai['categories'].str.contains('FinTech', na=False, case=False),\n",
    "    'Blockchain': df_ai['categories'].str.contains('Blockchain', na=False, case=False),\n",
    "    'Robotics': df_ai['categories'].str.contains('Robotics', na=False, case=False),\n",
    "}\n",
    "\n",
    "sector_stats = []\n",
    "for sector_name, mask in sectors.items():\n",
    "    sector_df = df_ai[mask]\n",
    "    if len(sector_df) > 0:\n",
    "        sector_ai = sector_df['mentions_ai'].sum()\n",
    "        pct_ai = (sector_ai / len(sector_df)) * 100\n",
    "        sector_stats.append({\n",
    "            'Sector': sector_name,\n",
    "            'Total': len(sector_df),\n",
    "            'Mentions AI': sector_ai,\n",
    "            'Percentage': pct_ai\n",
    "        })\n",
    "        print(f\"{sector_name}:\")\n",
    "        print(f\"  Total Companies: {len(sector_df):,}\")\n",
    "        print(f\"  Mentioning AI: {sector_ai:,} ({pct_ai:.2f}%)\")\n",
    "        print()\n",
    "\n",
    "# Export summary to CSV\n",
    "summary_data = {\n",
    "    'Metric': [\n",
    "        'Total Companies',\n",
    "        'Mentions AI in Description',\n",
    "        'Has AI Category',\n",
    "        'Both Description and Category',\n",
    "        'Either Description or Category',\n",
    "        'Description Only',\n",
    "        'Category Only',\n",
    "        'Neither'\n",
    "    ],\n",
    "    'Count': [\n",
    "        total_companies,\n",
    "        ai_in_description,\n",
    "        ai_in_category,\n",
    "        both_ai,\n",
    "        either_ai,\n",
    "        (df_ai['mentions_ai'] & ~df_ai['has_ai_category']).sum(),\n",
    "        (~df_ai['mentions_ai'] & df_ai['has_ai_category']).sum(),\n",
    "        (~df_ai['mentions_ai'] & ~df_ai['has_ai_category']).sum()\n",
    "    ],\n",
    "    'Percentage': [\n",
    "        100.0,\n",
    "        ai_in_description/total_companies*100,\n",
    "        ai_in_category/total_companies*100,\n",
    "        both_ai/total_companies*100,\n",
    "        either_ai/total_companies*100,\n",
    "        (df_ai['mentions_ai'] & ~df_ai['has_ai_category']).sum()/total_companies*100,\n",
    "        (~df_ai['mentions_ai'] & df_ai['has_ai_category']).sum()/total_companies*100,\n",
    "        (~df_ai['mentions_ai'] & ~df_ai['has_ai_category']).sum()/total_companies*100\n",
    "    ]\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "summary_df.to_csv('ai_mentions_summary.csv', index=False)\n",
    "print(\"=\" * 80)\n",
    "print(\"Summary saved to: ai_mentions_summary.csv\")\n",
    "\n",
    "# Export pattern breakdown\n",
    "pattern_df = pd.DataFrame([\n",
    "    {'Pattern': pattern.replace('_', ' ').title(), 'Count': count, 'Percentage': count/total_companies*100}\n",
    "    for pattern, count in sorted_patterns\n",
    "])\n",
    "pattern_df.to_csv('ai_patterns_breakdown.csv', index=False)\n",
    "print(\"Pattern breakdown saved to: ai_patterns_breakdown.csv\")\n",
    "\n",
    "# Export sector breakdown\n",
    "sector_df = pd.DataFrame(sector_stats)\n",
    "sector_df.to_csv('ai_sector_breakdown.csv', index=False)\n",
    "print(\"Sector breakdown saved to: ai_sector_breakdown.csv\")\n",
    "\n",
    "# Export list of AI companies\n",
    "ai_companies_export = df_ai[df_ai['mentions_ai']][['name', 'short_description', 'categories', 'founded_date']].copy()\n",
    "if 'employees_midpoint' in df_ai.columns:\n",
    "    ai_companies_export['employees_midpoint'] = df_ai[df_ai['mentions_ai']]['employees_midpoint']\n",
    "ai_companies_export = ai_companies_export.sort_values('name')\n",
    "ai_companies_export.to_csv('companies_mentioning_ai.csv', index=False)\n",
    "print(f\"List of {len(ai_companies_export):,} companies mentioning AI saved to: companies_mentioning_ai.csv\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ANALYSIS COMPLETE!\")\n",
    "print(\"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9060b65a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "AI MENTIONS IN COMPANY DESCRIPTIONS - ANALYSIS SUMMARY\n",
      "================================================================================\n",
      "\n",
      "Generated: 2025-11-15 12:09:32\n",
      "\n",
      "OVERALL STATISTICS\n",
      "--------------------------------------------------------------------------------\n",
      "Total Companies Analyzed: 26,012\n",
      "Companies Mentioning AI in Description: 6,693 (25.73%)\n",
      "Companies with AI Category: 5,036 (19.36%)\n",
      "Companies with Both Description & Category: 3,790\n",
      "Companies with Either Description OR Category: 7,939 (30.52%)\n",
      "Description Only (no AI category): 2,903\n",
      "Category Only (no AI in description): 1,246\n",
      "Neither Description nor Category: 18,073\n",
      "\n",
      "AI TERMINOLOGY BREAKDOWN\n",
      "--------------------------------------------------------------------------------\n",
      "  Ai Direct                     :  6,338 companies (24.37%)\n",
      "  Ai Powered                    :  1,699 companies ( 6.53%)\n",
      "  Artificial Intelligence       :    367 companies ( 1.41%)\n",
      "  Generative Ai                 :    201 companies ( 0.77%)\n",
      "  Machine Learning              :    126 companies ( 0.48%)\n",
      "  Ai Native                     :     81 companies ( 0.31%)\n",
      "  Ai Agent                      :     80 companies ( 0.31%)\n",
      "  Llm                           :     68 companies ( 0.26%)\n",
      "  Computer Vision               :     32 companies ( 0.12%)\n",
      "  Nlp                           :     12 companies ( 0.05%)\n",
      "  Deep Learning                 :      8 companies ( 0.03%)\n",
      "  Neural Network                :      1 companies ( 0.00%)\n",
      "\n",
      "SECTOR-SPECIFIC AI MENTIONS\n",
      "--------------------------------------------------------------------------------\n",
      "Software:\n",
      "  Total Companies: 5,552\n",
      "  Mentioning AI: 2,307 (41.55%)\n",
      "\n",
      "SaaS:\n",
      "  Total Companies: 1,896\n",
      "  Mentioning AI: 824 (43.46%)\n",
      "\n",
      "Health Care:\n",
      "  Total Companies: 1,302\n",
      "  Mentioning AI: 355 (27.27%)\n",
      "\n",
      "FinTech:\n",
      "  Total Companies: 814\n",
      "  Mentioning AI: 198 (24.32%)\n",
      "\n",
      "Blockchain:\n",
      "  Total Companies: 620\n",
      "  Mentioning AI: 118 (19.03%)\n",
      "\n",
      "Robotics:\n",
      "  Total Companies: 234\n",
      "  Mentioning AI: 79 (33.76%)\n",
      "\n",
      "================================================================================\n",
      "Summary saved to: ai_mentions_summary.csv\n",
      "Pattern breakdown saved to: ai_patterns_breakdown.csv\n",
      "Sector breakdown saved to: ai_sector_breakdown.csv\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['founded_date'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 165\u001b[39m\n",
      "\u001b[32m    162\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mSector breakdown saved to: ai_sector_breakdown.csv\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[32m    164\u001b[39m \u001b[38;5;66;03m# Export list of AI companies\u001b[39;00m\n",
      "\u001b[32m--> \u001b[39m\u001b[32m165\u001b[39m ai_companies_export = \u001b[43mdf_ai\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdf_ai\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmentions_ai\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mname\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mshort_description\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcategories\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mfounded_date\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m.copy()\n",
      "\u001b[32m    166\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33memployees_midpoint\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m df_ai.columns:\n",
      "\u001b[32m    167\u001b[39m     ai_companies_export[\u001b[33m'\u001b[39m\u001b[33memployees_midpoint\u001b[39m\u001b[33m'\u001b[39m] = df_ai[df_ai[\u001b[33m'\u001b[39m\u001b[33mmentions_ai\u001b[39m\u001b[33m'\u001b[39m]][\u001b[33m'\u001b[39m\u001b[33memployees_midpoint\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Research/.venv/lib/python3.14/site-packages/pandas/core/frame.py:4119\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n",
      "\u001b[32m   4117\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "\u001b[32m   4118\u001b[39m         key = \u001b[38;5;28mlist\u001b[39m(key)\n",
      "\u001b[32m-> \u001b[39m\u001b[32m4119\u001b[39m     indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumns\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m]\n",
      "\u001b[32m   4121\u001b[39m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n",
      "\u001b[32m   4122\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mbool\u001b[39m:\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Research/.venv/lib/python3.14/site-packages/pandas/core/indexes/base.py:6212\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n",
      "\u001b[32m   6209\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[32m   6210\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n",
      "\u001b[32m-> \u001b[39m\u001b[32m6212\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m   6214\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n",
      "\u001b[32m   6215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n",
      "\u001b[32m   6216\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Research/.venv/lib/python3.14/site-packages/pandas/core/indexes/base.py:6264\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n",
      "\u001b[32m   6261\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[32m   6263\u001b[39m not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n",
      "\u001b[32m-> \u001b[39m\u001b[32m6264\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\n",
      "\u001b[31mKeyError\u001b[39m: \"['founded_date'] not in index\""
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# AI MENTIONS ANALYSIS - FOCUSED ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "def analyze_ai_mentions_focused(df):\n",
    "    \"\"\"Comprehensive analysis of AI mentions in descriptions\"\"\"\n",
    "    \n",
    "    # Define AI-related patterns\n",
    "    ai_patterns = {\n",
    "        'ai_direct': r'\\bai\\b',\n",
    "        'artificial_intelligence': r'\\bartificial intelligence\\b',\n",
    "        'machine_learning': r'\\bmachine learning\\b|\\bml\\b',\n",
    "        'deep_learning': r'\\bdeep learning\\b',\n",
    "        'neural_network': r'\\bneural network\\b',\n",
    "        'llm': r'\\bllm\\b|\\blarge language model\\b',\n",
    "        'generative_ai': r'\\bgenerative ai\\b|\\bgenai\\b',\n",
    "        'computer_vision': r'\\bcomputer vision\\b',\n",
    "        'nlp': r'\\bnlp\\b|\\bnatural language processing\\b',\n",
    "        'ai_powered': r'\\bai.powered\\b|\\bai.driven\\b',\n",
    "        'ai_native': r'\\bai.native\\b',\n",
    "        'ai_agent': r'\\bai agent\\b',\n",
    "    }\n",
    "    \n",
    "    # Check for any AI mention (broad)\n",
    "    broad_ai_pattern = r'\\bai\\b|\\bartificial intelligence\\b|\\bmachine learning\\b|\\bdeep learning\\b|\\bneural\\b|\\bllm\\b|\\bgenerative ai\\b|\\bgenai\\b'\n",
    "    df['mentions_ai'] = df['short_description'].str.contains(broad_ai_pattern, case=False, na=False, regex=True)\n",
    "    \n",
    "    # Check for AI category\n",
    "    df['has_ai_category'] = df['categories'].str.contains('Artificial Intelligence', na=False, case=False)\n",
    "    \n",
    "    # Detailed pattern matching\n",
    "    pattern_counts = {}\n",
    "    for pattern_name, pattern in ai_patterns.items():\n",
    "        mask = df['short_description'].str.contains(pattern, case=False, na=False, regex=True)\n",
    "        pattern_counts[pattern_name] = mask.sum()\n",
    "    \n",
    "    return df, pattern_counts\n",
    "\n",
    "# Run analysis\n",
    "df_ai, pattern_counts = analyze_ai_mentions_focused(df)\n",
    "\n",
    "# Calculate statistics\n",
    "total_companies = len(df_ai)\n",
    "ai_in_description = df_ai['mentions_ai'].sum()\n",
    "ai_in_category = df_ai['has_ai_category'].sum()\n",
    "both_ai = (df_ai['mentions_ai'] & df_ai['has_ai_category']).sum()\n",
    "either_ai = (df_ai['mentions_ai'] | df_ai['has_ai_category']).sum()\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"AI MENTIONS IN COMPANY DESCRIPTIONS - ANALYSIS SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nGenerated: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "\n",
    "print(\"OVERALL STATISTICS\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"Total Companies Analyzed: {total_companies:,}\")\n",
    "print(f\"Companies Mentioning AI in Description: {ai_in_description:,} ({ai_in_description/total_companies*100:.2f}%)\")\n",
    "print(f\"Companies with AI Category: {ai_in_category:,} ({ai_in_category/total_companies*100:.2f}%)\")\n",
    "print(f\"Companies with Both Description & Category: {both_ai:,}\")\n",
    "print(f\"Companies with Either Description OR Category: {either_ai:,} ({either_ai/total_companies*100:.2f}%)\")\n",
    "print(f\"Description Only (no AI category): {(df_ai['mentions_ai'] & ~df_ai['has_ai_category']).sum():,}\")\n",
    "print(f\"Category Only (no AI in description): {(~df_ai['mentions_ai'] & df_ai['has_ai_category']).sum():,}\")\n",
    "print(f\"Neither Description nor Category: {(~df_ai['mentions_ai'] & ~df_ai['has_ai_category']).sum():,}\")\n",
    "\n",
    "print(\"\\nAI TERMINOLOGY BREAKDOWN\")\n",
    "print(\"-\" * 80)\n",
    "sorted_patterns = sorted(pattern_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "for pattern, count in sorted_patterns:\n",
    "    pct = (count / total_companies) * 100\n",
    "    print(f\"  {pattern.replace('_', ' ').title():30s}: {count:6,} companies ({pct:5.2f}%)\")\n",
    "\n",
    "# Company size analysis for AI companies\n",
    "ai_companies = df_ai[df_ai['mentions_ai']]\n",
    "if len(ai_companies) > 0 and 'employees_midpoint' in ai_companies.columns:\n",
    "    print(\"\\nAI COMPANY SIZE ANALYSIS\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"Average Employees (AI Companies): {ai_companies['employees_midpoint'].mean():.1f}\")\n",
    "    print(f\"Median Employees (AI Companies): {ai_companies['employees_midpoint'].median():.1f}\")\n",
    "    print(f\"Small Companies (1-10 employees): {(ai_companies['employees_min'] <= 10).sum():,}\")\n",
    "    print(f\"Medium Companies (11-50 employees): {((ai_companies['employees_min'] > 10) & (ai_companies['employees_max'] <= 50)).sum():,}\")\n",
    "    print(f\"Large Companies (51+ employees): {(ai_companies['employees_min'] > 50).sum():,}\")\n",
    "\n",
    "# Sector analysis\n",
    "print(\"\\nSECTOR-SPECIFIC AI MENTIONS\")\n",
    "print(\"-\" * 80)\n",
    "sectors = {\n",
    "    'Software': df_ai['categories'].str.contains('Software', na=False, case=False),\n",
    "    'SaaS': df_ai['categories'].str.contains('SaaS', na=False, case=False),\n",
    "    'Health Care': df_ai['categories'].str.contains('Health Care', na=False, case=False),\n",
    "    'FinTech': df_ai['categories'].str.contains('FinTech', na=False, case=False),\n",
    "    'Blockchain': df_ai['categories'].str.contains('Blockchain', na=False, case=False),\n",
    "    'Robotics': df_ai['categories'].str.contains('Robotics', na=False, case=False),\n",
    "}\n",
    "\n",
    "sector_stats = []\n",
    "for sector_name, mask in sectors.items():\n",
    "    sector_df = df_ai[mask]\n",
    "    if len(sector_df) > 0:\n",
    "        sector_ai = sector_df['mentions_ai'].sum()\n",
    "        pct_ai = (sector_ai / len(sector_df)) * 100\n",
    "        sector_stats.append({\n",
    "            'Sector': sector_name,\n",
    "            'Total': len(sector_df),\n",
    "            'Mentions AI': sector_ai,\n",
    "            'Percentage': pct_ai\n",
    "        })\n",
    "        print(f\"{sector_name}:\")\n",
    "        print(f\"  Total Companies: {len(sector_df):,}\")\n",
    "        print(f\"  Mentioning AI: {sector_ai:,} ({pct_ai:.2f}%)\")\n",
    "        print()\n",
    "\n",
    "# Export summary to CSV\n",
    "summary_data = {\n",
    "    'Metric': [\n",
    "        'Total Companies',\n",
    "        'Mentions AI in Description',\n",
    "        'Has AI Category',\n",
    "        'Both Description and Category',\n",
    "        'Either Description or Category',\n",
    "        'Description Only',\n",
    "        'Category Only',\n",
    "        'Neither'\n",
    "    ],\n",
    "    'Count': [\n",
    "        total_companies,\n",
    "        ai_in_description,\n",
    "        ai_in_category,\n",
    "        both_ai,\n",
    "        either_ai,\n",
    "        (df_ai['mentions_ai'] & ~df_ai['has_ai_category']).sum(),\n",
    "        (~df_ai['mentions_ai'] & df_ai['has_ai_category']).sum(),\n",
    "        (~df_ai['mentions_ai'] & ~df_ai['has_ai_category']).sum()\n",
    "    ],\n",
    "    'Percentage': [\n",
    "        100.0,\n",
    "        ai_in_description/total_companies*100,\n",
    "        ai_in_category/total_companies*100,\n",
    "        both_ai/total_companies*100,\n",
    "        either_ai/total_companies*100,\n",
    "        (df_ai['mentions_ai'] & ~df_ai['has_ai_category']).sum()/total_companies*100,\n",
    "        (~df_ai['mentions_ai'] & df_ai['has_ai_category']).sum()/total_companies*100,\n",
    "        (~df_ai['mentions_ai'] & ~df_ai['has_ai_category']).sum()/total_companies*100\n",
    "    ]\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "summary_df.to_csv('ai_mentions_summary.csv', index=False)\n",
    "print(\"=\" * 80)\n",
    "print(\"Summary saved to: ai_mentions_summary.csv\")\n",
    "\n",
    "# Export pattern breakdown\n",
    "pattern_df = pd.DataFrame([\n",
    "    {'Pattern': pattern.replace('_', ' ').title(), 'Count': count, 'Percentage': count/total_companies*100}\n",
    "    for pattern, count in sorted_patterns\n",
    "])\n",
    "pattern_df.to_csv('ai_patterns_breakdown.csv', index=False)\n",
    "print(\"Pattern breakdown saved to: ai_patterns_breakdown.csv\")\n",
    "\n",
    "# Export sector breakdown\n",
    "sector_df = pd.DataFrame(sector_stats)\n",
    "sector_df.to_csv('ai_sector_breakdown.csv', index=False)\n",
    "print(\"Sector breakdown saved to: ai_sector_breakdown.csv\")\n",
    "\n",
    "# Export list of AI companies\n",
    "ai_companies_export = df_ai[df_ai['mentions_ai']][['name', 'short_description', 'categories', 'founded_date']].copy()\n",
    "if 'employees_midpoint' in df_ai.columns:\n",
    "    ai_companies_export['employees_midpoint'] = df_ai[df_ai['mentions_ai']]['employees_midpoint']\n",
    "ai_companies_export = ai_companies_export.sort_values('name')\n",
    "ai_companies_export.to_csv('companies_mentioning_ai.csv', index=False)\n",
    "print(f\"List of {len(ai_companies_export):,} companies mentioning AI saved to: companies_mentioning_ai.csv\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ANALYSIS COMPLETE!\")\n",
    "print(\"=\" * 80)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
